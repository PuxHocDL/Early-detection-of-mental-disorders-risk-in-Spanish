{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 35972,
     "status": "ok",
     "timestamp": 1744013153366,
     "user": {
      "displayName": "Ph√∫c Nguy·ªÖn Xu√¢n",
      "userId": "14670273794783355842"
     },
     "user_tz": -420
    },
    "id": "NfcR90bVFpFK"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import emoji\n",
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from tabulate import tabulate\n",
    "from colorama import init, Fore, Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UqC7SVG3Vi0r"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T·∫•t c·∫£ c√°c bi·ªÉu t∆∞·ª£ng c·∫£m x√∫c trong d·ªØ li·ªáu:\n",
      "ü´Ä - :anatomical_heart:\n",
      "üò± - :face_screaming_in_fear:\n",
      "üáÆüá≥ - :India:\n",
      "üéâ - :party_popper:\n",
      "üê¨ - :dolphin:\n",
      "ü•≥ - :partying_face:\n",
      "üòâ - :winking_face:\n",
      "‚õî - :no_entry:\n",
      "üöÄ - :rocket:\n",
      "üò∂ - :face_without_mouth:\n",
      "üëåüèº - :OK_hand_medium-light_skin_tone:\n",
      "üëÜ - :backhand_index_pointing_up:\n",
      "üò† - :angry_face:\n",
      "üåö - :new_moon_face:\n",
      "üòï - :confused_face:\n",
      "ü§¶üèª‚Äç‚ôÇ - :man_facepalming_light_skin_tone:\n",
      "üëÜüèΩ - :backhand_index_pointing_up_medium_skin_tone:\n",
      "üêª - :bear:\n",
      "üò¥ - :sleeping_face:\n",
      "üí∂ - :euro_banknote:\n",
      "üòî - :pensive_face:\n",
      "üôà - :see-no-evil_monkey:\n",
      "ü•∫ - :pleading_face:\n",
      "üò™ - :sleepy_face:\n",
      "ü¶ñ - :T-Rex:\n",
      "üí∞ - :money_bag:\n",
      "ü•ö - :egg:\n",
      "üçé - :red_apple:\n",
      "‚úÖ - :check_mark_button:\n",
      "üòÆ - :face_with_open_mouth:\n",
      "‚òπ - :frowning_face:\n",
      "üëè - :clapping_hands:\n",
      "‚ô• - :heart_suit:\n",
      "üò® - :fearful_face:\n",
      "ü§¶üèª‚Äç‚ôÄ - :woman_facepalming_light_skin_tone:\n",
      "üî™ - :kitchen_knife:\n",
      "‚ùó - :red_exclamation_mark:\n",
      "üêÆ - :cow_face:\n",
      "üéà - :balloon:\n",
      "üìä - :bar_chart:\n",
      "üëèüèª - :clapping_hands_light_skin_tone:\n",
      "üìà - :chart_increasing:\n",
      "üü£ - :purple_circle:\n",
      "üò≥ - :flushed_face:\n",
      "üòÅ - :beaming_face_with_smiling_eyes:\n",
      "üê≥ - :spouting_whale:\n",
      "üëº - :baby_angel:\n",
      "üçè - :green_apple:\n",
      "üîù - :TOP_arrow:\n",
      "ü§ô - :call_me_hand:\n",
      "üö∂üèª‚Äç‚ôÇ - :man_walking_light_skin_tone:\n",
      "ü§® - :face_with_raised_eyebrow:\n",
      "üí™ - :flexed_biceps:\n",
      "üëâ - :backhand_index_pointing_right:\n",
      "ü§¶‚Äç‚ôÇ - :man_facepalming:\n",
      "ü´µ - :index_pointing_at_the_viewer:\n",
      "üåä - :water_wave:\n",
      "ü•∞ - :smiling_face_with_hearts:\n",
      "ü§ë - :money-mouth_face:\n",
      "üòì - :downcast_face_with_sweat:\n",
      "üêü - :fish:\n",
      "üéÑ - :Christmas_tree:\n",
      "üî¥ - :red_circle:\n",
      "üá∫üá¶ - :Ukraine:\n",
      "üá∫üá∏ - :United_States:\n",
      "üíã - :kiss_mark:\n",
      "‚úå - :victory_hand:\n",
      "‚¨Ü - :up_arrow:\n",
      "üò≤ - :astonished_face:\n",
      "3Ô∏è‚É£ - :keycap_3:\n",
      "üí© - :pile_of_poo:\n",
      "üòí - :unamused_face:\n",
      "üò∂‚Äçüå´ - :face_in_clouds:\n",
      "üáßüá¨ - :Bulgaria:\n",
      "‚úåüèΩ - :victory_hand_medium_skin_tone:\n",
      "ü§∑üèª‚Äç‚ôÇ - :man_shrugging_light_skin_tone:\n",
      "üá¶üá∑ - :Argentina:\n",
      "üá≥üá¨ - :Nigeria:\n",
      "üëçüèæ - :thumbs_up_medium-dark_skin_tone:\n",
      "üôÑ - :face_with_rolling_eyes:\n",
      "üéæ - :tennis:\n",
      "üòè - :smirking_face:\n",
      "üá™üá∏ - :Spain:\n",
      "üôèüèª - :folded_hands_light_skin_tone:\n",
      "‚òÄ - :sun:\n",
      "üç∫ - :beer_mug:\n",
      "üëç - :thumbs_up:\n",
      "ü•π - :face_holding_back_tears:\n",
      "üßê - :face_with_monocle:\n",
      "üñêüèΩ - :hand_with_fingers_splayed_medium_skin_tone:\n",
      "‚òùüèª - :index_pointing_up_light_skin_tone:\n",
      "üé∂ - :musical_notes:\n",
      "ü§ù - :handshake:\n",
      "ü§£ - :rolling_on_the_floor_laughing:\n",
      "üôãüèª‚Äç‚ôÄ - :woman_raising_hand_light_skin_tone:\n",
      "üòÖ - :grinning_face_with_sweat:\n",
      "‚ö∞ - :coffin:\n",
      "1Ô∏è‚É£ - :keycap_1:\n",
      "ü´§ - :face_with_diagonal_mouth:\n",
      "üôÄ - :weary_cat:\n",
      "üôÇ - :slightly_smiling_face:\n",
      "ü™ú - :ladder:\n",
      "ü§ß - :sneezing_face:\n",
      "ü§∑üèΩ‚Äç‚ôÄ - :woman_shrugging_medium_skin_tone:\n",
      "üò• - :sad_but_relieved_face:\n",
      "üòØ - :hushed_face:\n",
      "üíÉ - :woman_dancing:\n",
      "üî• - :fire:\n",
      "üí™üèº - :flexed_biceps_medium-light_skin_tone:\n",
      "4Ô∏è‚É£ - :keycap_4:\n",
      "üîª - :red_triangle_pointed_down:\n",
      "ü§Æ - :face_vomiting:\n",
      "üòÜ - :grinning_squinting_face:\n",
      "ü§î - :thinking_face:\n",
      "üõç - :shopping_bags:\n",
      "‚úåüèª - :victory_hand_light_skin_tone:\n",
      "ü§å - :pinched_fingers:\n",
      "üòë - :expressionless_face:\n",
      "üòä - :smiling_face_with_smiling_eyes:\n",
      "‚ö† - :warning:\n",
      "ü§∑ - :person_shrugging:\n",
      "üôå - :raising_hands:\n",
      "‚è∫ - :record_button:\n",
      "üéÇ - :birthday_cake:\n",
      "üëã - :waving_hand:\n",
      "üôåüèΩ - :raising_hands_medium_skin_tone:\n",
      "üîµ - :blue_circle:\n",
      "ü§∑üèº‚Äç‚ôÇ - :man_shrugging_medium-light_skin_tone:\n",
      "üñêüèº - :hand_with_fingers_splayed_medium-light_skin_tone:\n",
      "üå¨ - :wind_face:\n",
      "‚ùå - :cross_mark:\n",
      "‚ù£ - :heart_exclamation:\n",
      "üëåüèΩ - :OK_hand_medium_skin_tone:\n",
      "‚Äº - :double_exclamation_mark:\n",
      "ü§ì - :nerd_face:\n",
      "üëÅ - :eye:\n",
      "üçÄ - :four_leaf_clover:\n",
      "üëèüèº - :clapping_hands_medium-light_skin_tone:\n",
      "üéµ - :musical_note:\n",
      "üôè - :folded_hands:\n",
      "ü§¶üèΩ‚Äç‚ôÇ - :man_facepalming_medium_skin_tone:\n",
      "ü¶• - :sloth:\n",
      "üéÅ - :wrapped_gift:\n",
      "üí≤ - :heavy_dollar_sign:\n",
      "üòª - :smiling_cat_with_heart-eyes:\n",
      "üòµ‚Äçüí´ - :face_with_spiral_eyes:\n",
      "üßòüèª‚Äç‚ôÇ - :man_in_lotus_position_light_skin_tone:\n",
      "üàö - :Japanese_free_of_charge_button:\n",
      "üîë - :key:\n",
      "üé¢ - :roller_coaster:\n",
      "ü§™ - :zany_face:\n",
      "üêÄ - :rat:\n",
      "üí™üèª - :flexed_biceps_light_skin_tone:\n",
      "ü§© - :star-struck:\n",
      "üòò - :face_blowing_a_kiss:\n",
      "üòÇ - :face_with_tears_of_joy:\n",
      "üò° - :enraged_face:\n",
      "‚úã - :raised_hand:\n",
      "‚ö° - :high_voltage:\n",
      "üåï - :full_moon:\n",
      "üü¢ - :green_circle:\n",
      "üê∏ - :frog:\n",
      "‚ù§ - :red_heart:\n",
      "‚ú® - :sparkles:\n",
      "ü•∏ - :disguised_face:\n",
      "ü§∑üèº‚Äç‚ôÄ - :woman_shrugging_medium-light_skin_tone:\n",
      "‚úä - :raised_fist:\n",
      "üéÖüèª - :Santa_Claus_light_skin_tone:\n",
      "‚¨á - :down_arrow:\n",
      "ü•í - :cucumber:\n",
      "üòù - :squinting_face_with_tongue:\n",
      "‚ò∫ - :smiling_face:\n",
      "üåñ - :waning_gibbous_moon:\n",
      "ü§Ø - :exploding_head:\n",
      "üòà - :smiling_face_with_horns:\n",
      "üîπ - :small_blue_diamond:\n",
      "üòÄ - :grinning_face:\n",
      "üòç - :smiling_face_with_heart-eyes:\n",
      "üí´ - :dizzy:\n",
      "üíµ - :dollar_banknote:\n",
      "ü§≠ - :face_with_hand_over_mouth:\n",
      "‚òù - :index_pointing_up:\n",
      "üì® - :incoming_envelope:\n",
      "üëàüèª - :backhand_index_pointing_left_light_skin_tone:\n",
      "üò≠ - :loudly_crying_face:\n",
      "üíé - :gem_stone:\n",
      "üî∞ - :Japanese_symbol_for_beginner:\n",
      "üôÉ - :upside-down_face:\n",
      "ü§ûüèª - :crossed_fingers_light_skin_tone:\n",
      "üëÖ - :tongue:\n",
      "üá∑üá∫ - :Russia:\n",
      "‚öΩ - :soccer_ball:\n",
      "üòã - :face_savoring_food:\n",
      "üëå - :OK_hand:\n",
      "üåé - :globe_showing_Americas:\n",
      "ü§° - :clown_face:\n",
      "üòπ - :cat_with_tears_of_joy:\n",
      "üí• - :collision:\n",
      "üá®üá≥ - :China:\n",
      "ü§¶üèΩ - :person_facepalming_medium_skin_tone:\n",
      "üê∑ - :pig_face:\n",
      "üôèüèΩ - :folded_hands_medium_skin_tone:\n",
      "üåå - :milky_way:\n",
      "üòõ - :face_with_tongue:\n",
      "üòæ - :pouting_cat:\n",
      "ü§ü - :love-you_gesture:\n",
      "üëª - :ghost:\n",
      "ü™Ç - :parachute:\n",
      "üòû - :disappointed_face:\n",
      "üï∫ - :man_dancing:\n",
      "üéº - :musical_score:\n",
      "üôÜ‚Äç‚ôÇ - :man_gesturing_OK:\n",
      "ü§ó - :smiling_face_with_open_hands:\n",
      "üôã‚Äç‚ôÇ - :man_raising_hand:\n",
      "‚úî - :check_mark:\n",
      "üåô - :crescent_moon:\n",
      "üçª - :clinking_beer_mugs:\n",
      "üáßüáæ - :Belarus:\n",
      "ü§ôüèª - :call_me_hand_light_skin_tone:\n",
      "ü´° - :saluting_face:\n",
      "üö´ - :prohibited:\n",
      "üëà - :backhand_index_pointing_left:\n",
      "üí® - :dashing_away:\n",
      "üôåüèº - :raising_hands_medium-light_skin_tone:\n",
      "ü§ûüèº - :crossed_fingers_medium-light_skin_tone:\n",
      "ü§ò - :sign_of_the_horns:\n",
      "üåê - :globe_with_meridians:\n",
      "üòê - :neutral_face:\n",
      "ü§¶üèº‚Äç‚ôÇ - :man_facepalming_medium-light_skin_tone:\n",
      "‚ñ∂ - :play_button:\n",
      "üí¨ - :speech_balloon:\n",
      "ü•∂ - :cold_face:\n",
      "‚úäüèº - :raised_fist_medium-light_skin_tone:\n",
      "üò∞ - :anxious_face_with_sweat:\n",
      "ü´£ - :face_with_peeking_eye:\n",
      "üí™üèΩ - :flexed_biceps_medium_skin_tone:\n",
      "ü•¥ - :woozy_face:\n",
      "ü§† - :cowboy_hat_face:\n",
      "‚ÑπÔ∏è - :information:\n",
      "üò¨ - :grimacing_face:\n",
      "üôãüèª‚Äç‚ôÇ - :man_raising_hand_light_skin_tone:\n",
      "üëçüèª - :thumbs_up_light_skin_tone:\n",
      "‚ùì - :red_question_mark:\n",
      "üëçüèº - :thumbs_up_medium-light_skin_tone:\n",
      "üëãüèª - :waving_hand_light_skin_tone:\n",
      "üíî - :broken_heart:\n",
      "üëèüèæ - :clapping_hands_medium-dark_skin_tone:\n",
      "üö® - :police_car_light:\n",
      "‚öì - :anchor:\n",
      "üòö - :kissing_face_with_closed_eyes:\n",
      "ü§üüèª - :love-you_gesture_light_skin_tone:\n",
      "üíö - :green_heart:\n",
      "ü•µ - :hot_face:\n",
      "ü§§ - :drooling_face:\n",
      "üòÉ - :grinning_face_with_big_eyes:\n",
      "üëÜüèº - :backhand_index_pointing_up_medium-light_skin_tone:\n",
      "üí∏ - :money_with_wings:\n",
      "üëâüèª - :backhand_index_pointing_right_light_skin_tone:\n",
      "ü§û - :crossed_fingers:\n",
      "üêó - :boar:\n",
      "üëÄ - :eyes:\n",
      "üáµüá™ - :Peru:\n",
      "üê∂ - :dog_face:\n",
      "üòé - :smiling_face_with_sunglasses:\n",
      "üò¢ - :crying_face:\n",
      "üòú - :winking_face_with_tongue:\n",
      "üòÑ - :grinning_face_with_smiling_eyes:\n",
      "üëåüèª - :OK_hand_light_skin_tone:\n",
      "üí¶ - :sweat_droplets:\n",
      "ü•± - :yawning_face:\n",
      "üôåüèª - :raising_hands_light_skin_tone:\n",
      "üåù - :full_moon_face:\n",
      "üòå - :relieved_face:\n",
      "üòá - :smiling_face_with_halo:\n",
      "üíØ - :hundred_points:\n",
      "ü§ôüèΩ - :call_me_hand_medium_skin_tone:\n",
      "ü§∑‚Äç‚ôÇ - :man_shrugging:\n",
      "üîÆ - :crystal_ball:\n",
      "üêÅ - :mouse:\n",
      "üåò - :waning_crescent_moon:\n",
      "üôä - :speak-no-evil_monkey:\n",
      "üëé - :thumbs_down:\n",
      "‚úà - :airplane:\n",
      "ü•≤ - :smiling_face_with_tear:\n",
      "üó£ - :speaking_head:\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"data/task1/train/subjects\"\n",
    "subjects = defaultdict(list)\n",
    "\n",
    "def extract_emojis(text):\n",
    "    return set(emoji_data['emoji'] for emoji_data in emoji.emoji_list(text))\n",
    "\n",
    "all_emojis = set()\n",
    "for filename in os.listdir(data_dir):\n",
    "    if filename.endswith(\".json\"):\n",
    "        with open(os.path.join(data_dir, filename), \"r\") as f:\n",
    "            messages = json.load(f)\n",
    "            nick = filename.split(\".\")[0]\n",
    "            for msg in messages:\n",
    "                message_text = str(msg[\"message\"]) if msg[\"message\"] is not None else \"\"\n",
    "                all_emojis.update(extract_emojis(message_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8115,
     "status": "ok",
     "timestamp": 1744013407276,
     "user": {
      "displayName": "Ph√∫c Nguy·ªÖn Xu√¢n",
      "userId": "14670273794783355842"
     },
     "user_tz": -420
    },
    "id": "tAGUiFCsZqls"
   },
   "outputs": [],
   "source": [
    "def map_emoji_to_spanish(emoji=None):\n",
    "    emoji_map = {\n",
    "        \"üîù\": \"arriba\",\n",
    "        \"üëé\": \"no me gusta\",\n",
    "        \"üò≥\": \"sorprendido\",\n",
    "        \"4Ô∏è‚É£\": \"cuatro\",\n",
    "        \"üñêüèº\": \"mano abierta\",\n",
    "        \"üíé\": \"diamante\",\n",
    "        \"ü§£\": \"riendo fuerte\",\n",
    "        \"ü§ûüèª\": \"dedos cruzados\",\n",
    "        \"üç∫\": \"cerveza\",\n",
    "        \"‚ù£\": \"coraz√≥n exclamaci√≥n\",\n",
    "        \"ü§°\": \"payaso\",\n",
    "        \"üéÖüèª\": \"Pap√° Noel\",\n",
    "        \"‚¨Ü\": \"subir\",\n",
    "        \"üí∏\": \"dinero volando\",\n",
    "        \"ü§§\": \"babeando\",\n",
    "        \"‚ùå\": \"cruz\",\n",
    "        \"üôåüèª\": \"manos arriba\",\n",
    "        \"ü§©\": \"asombrado\",\n",
    "        \"üáµüá™\": \"Per√∫\",\n",
    "        \"ü§†\": \"vaquero\",\n",
    "        \"üü£\": \"c√≠rculo morado\",\n",
    "        \"üñêüèΩ\": \"mano abierta\",\n",
    "        \"üôÉ\": \"cara invertida\",\n",
    "        \"üê∏\": \"rana\",\n",
    "        \"üëÜüèº\": \"se√±alando arriba\",\n",
    "        \"üàö\": \"gratis\",\n",
    "        \"üåê\": \"mundo\",\n",
    "        \"üéÅ\": \"regalo\",\n",
    "        \"üéâ\": \"celebraci√≥n\",\n",
    "        \"üòµ‚Äçüí´\": \"mareado\",\n",
    "        \"üåù\": \"luna llena\",\n",
    "        \"üôã‚Äç‚ôÇ\": \"hombre levantando mano\",\n",
    "        \"3Ô∏è‚É£\": \"tres\",\n",
    "        \"üîÆ\": \"bola de cristal\",\n",
    "        \"üò∞\": \"nervioso\",\n",
    "        \"üò®\": \"miedo\",\n",
    "        \"‚ùì\": \"pregunta\",\n",
    "        \"‚òùüèª\": \"dedo arriba\",\n",
    "        \"ü•≤\": \"l√°grimas de alegr√≠a\",\n",
    "        \"‚úäüèº\": \"pu√±o levantado\",\n",
    "        \"‚úä\": \"pu√±o\",\n",
    "        \"üßòüèª‚Äç‚ôÇ\": \"meditaci√≥n\",\n",
    "        \"üßê\": \"curioso\",\n",
    "        \"üëèüèæ\": \"aplausos\",\n",
    "        \"üê≥\": \"ballena\",\n",
    "        \"üí™üèº\": \"fuerza\",\n",
    "        \"‚úÖ\": \"aprobado\",\n",
    "        \"ü§¶üèº‚Äç‚ôÇ\": \"verg√ºenza\",\n",
    "        \"üòç\": \"enamorado\",\n",
    "        \"üëª\": \"fantasma\",\n",
    "        \"üòÇ\": \"riendo\",\n",
    "        \"üí™üèª\": \"fuerte\",\n",
    "        \"ü´§\": \"decepci√≥n\",\n",
    "        \"‚öΩ\": \"f√∫tbol\",\n",
    "        \"ü•ö\": \"huevo\",\n",
    "        \"üôè\": \"rezando\",\n",
    "        \"ü§ô\": \"ll√°mame\",\n",
    "        \"üôÑ\": \"aburrido\",\n",
    "        \"üò≤\": \"asombro\",\n",
    "        \"‚ô•\": \"coraz√≥n\",\n",
    "        \"üçé\": \"manzana\",\n",
    "        \"üêª\": \"oso\",\n",
    "        \"ü§™\": \"loco\",\n",
    "        \"üëÜüèΩ\": \"se√±alando arriba\",\n",
    "        \"üé¢\": \"monta√±a rusa\",\n",
    "        \"üôå\": \"celebrando\",\n",
    "        \"üåò\": \"luna menguante\",\n",
    "        \"ü´°\": \"saludo\",\n",
    "        \"üôãüèª‚Äç‚ôÄ\": \"mujer levantando mano\",\n",
    "        \"ü§¶‚Äç‚ôÇ\": \"error\",\n",
    "        \"üåä\": \"ola\",\n",
    "        \"üòâ\": \"gui√±o\",\n",
    "        \"ü•∂\": \"fr√≠o\",\n",
    "        \"üíã\": \"beso\",\n",
    "        \"üá∫üá¶\": \"Ucrania\",\n",
    "        \"üò∂‚Äçüå´\": \"confundido\",\n",
    "        \"üå¨\": \"viento\",\n",
    "        \"üí©\": \"mierda\",\n",
    "        \"üëåüèº\": \"perfecto\",\n",
    "        \"üôÜ‚Äç‚ôÇ\": \"hombre OK\",\n",
    "        \"üí™üèΩ\": \"fuerza\",\n",
    "        \"üò±\": \"gritando\",\n",
    "        \"1Ô∏è‚É£\": \"uno\",\n",
    "        \"ü§ò\": \"rock\",\n",
    "        \"üëâ\": \"se√±alando derecha\",\n",
    "        \"üôÇ\": \"sonriendo\",\n",
    "        \"üëÅ\": \"ojo\",\n",
    "        \"üëÄ\": \"ojos\",\n",
    "        \"üî•\": \"fuego\",\n",
    "        \"‚è∫\": \"grabar\",\n",
    "        \"üòÖ\": \"sudando\",\n",
    "        \"‚ùó\": \"exclamaci√≥n\",\n",
    "        \"üòï\": \"confuso\",\n",
    "        \"ü•í\": \"pepino\",\n",
    "        \"üéÇ\": \"torta\",\n",
    "        \"üò•\": \"aliviado\",\n",
    "        \"‚úåüèΩ\": \"victoria\",\n",
    "        \"üéæ\": \"tenis\",\n",
    "        \"üíö\": \"coraz√≥n verde\",\n",
    "        \"üíî\": \"coraz√≥n roto\",\n",
    "        \"üëç\": \"bien\",\n",
    "        \"üê∂\": \"perro\",\n",
    "        \"‚úî\": \"verificado\",\n",
    "        \"‚úåüèª\": \"paz\",\n",
    "        \"üí™\": \"m√∫sculo\",\n",
    "        \"üéà\": \"globo\",\n",
    "        \"ü§ë\": \"dinero en la cara\",\n",
    "        \"üòæ\": \"gato enfadado\",\n",
    "        \"üíµ\": \"billete\",\n",
    "        \"üëãüèª\": \"saludando\",\n",
    "        \"üëàüèª\": \"se√±alando izquierda\",\n",
    "        \"üí∞\": \"bolsa de dinero\",\n",
    "        \"üéº\": \"m√∫sica\",\n",
    "        \"üêÆ\": \"vaca\",\n",
    "        \"üá¶üá∑\": \"Argentina\",\n",
    "        \"ü§∑üèº‚Äç‚ôÄ\": \"mujer encogi√©ndose\",\n",
    "        \"üíÉ\": \"bailando\",\n",
    "        \"ü§Æ\": \"vomitando\",\n",
    "        \"üá∑üá∫\": \"Rusia\",\n",
    "        \"üòé\": \"genial\",\n",
    "        \"ü•≥\": \"fiesta\",\n",
    "        \"‚ö∞\": \"ata√∫d\",\n",
    "        \"üíØ\": \"cien puntos\",\n",
    "        \"üìà\": \"gr√°fico subiendo\",\n",
    "        \"üò≠\": \"llorando\",\n",
    "        \"üò™\": \"somnoliento\",\n",
    "        \"ü§ûüèº\": \"suerte\",\n",
    "        \"ü§¶üèΩ‚Äç‚ôÇ\": \"hombre avergonzado\",\n",
    "        \"‚ñ∂\": \"reproducir\",\n",
    "        \"‚õî\": \"prohibido\",\n",
    "        \"üé∂\": \"notas musicales\",\n",
    "        \"üôä\": \"mono callado\",\n",
    "        \"üåö\": \"luna nueva\",\n",
    "        \"üëè\": \"aplaudiendo\",\n",
    "        \"üôèüèΩ\": \"rezando\",\n",
    "        \"üòÑ\": \"feliz\",\n",
    "        \"ü§¶üèª‚Äç‚ôÇ\": \"error hombre\",\n",
    "        \"üá®üá≥\": \"China\",\n",
    "        \"üëåüèª\": \"OK\",\n",
    "        \"ü§ôüèª\": \"ll√°mame\",\n",
    "        \"üá≥üá¨\": \"Nigeria\",\n",
    "        \"üòÉ\": \"alegre\",\n",
    "        \"‚ÑπÔ∏è\": \"informaci√≥n\",\n",
    "        \"üó£\": \"hablando\",\n",
    "        \"üôåüèº\": \"manos levantadas\",\n",
    "        \"ü§û\": \"cruzando dedos\",\n",
    "        \"üòú\": \"broma\",\n",
    "        \"üéµ\": \"nota musical\",\n",
    "        \"ü§ü\": \"te amo\",\n",
    "        \"‚úà\": \"avi√≥n\",\n",
    "        \"üëåüèΩ\": \"perfecto\",\n",
    "        \"ü§¶üèΩ\": \"verg√ºenza\",\n",
    "        \"üëçüèæ\": \"bien\",\n",
    "        \"üîπ\": \"diamante azul\",\n",
    "        \"üòù\": \"lengua fuera\",\n",
    "        \"üí∂\": \"euro\",\n",
    "        \"ü§ì\": \"nerd\",\n",
    "        \"üò∂\": \"sin expresi√≥n\",\n",
    "        \"üêÅ\": \"rat√≥n\",\n",
    "        \"üêó\": \"jabal√≠\",\n",
    "        \"ü§¶üèª‚Äç‚ôÄ\": \"mujer avergonzada\",\n",
    "        \"üçè\": \"manzana verde\",\n",
    "        \"üü¢\": \"c√≠rculo verde\",\n",
    "        \"üôåüèΩ\": \"celebraci√≥n\",\n",
    "        \"üá™üá∏\": \"Espa√±a\",\n",
    "        \"‚ú®\": \"brillo\",\n",
    "        \"ü§∑üèª‚Äç‚ôÇ\": \"hombre encogi√©ndose\",\n",
    "        \"üö®\": \"alarma\",\n",
    "        \"ü•∞\": \"amor\",\n",
    "        \"‚ò∫\": \"sonrisa\",\n",
    "        \"ü§∑‚Äç‚ôÇ\": \"duda\",\n",
    "        \"ü§Ø\": \"cabeza explotando\",\n",
    "        \"ü•∫\": \"suplicando\",\n",
    "        \"üêü\": \"pez\",\n",
    "        \"üáÆüá≥\": \"India\",\n",
    "        \"üòê\": \"neutral\",\n",
    "        \"üòÅ\": \"sonriendo amplio\",\n",
    "        \"üôãüèª‚Äç‚ôÇ\": \"levantando mano\",\n",
    "        \"üòì\": \"sudor\",\n",
    "        \"üï∫\": \"bailando\",\n",
    "        \"üòØ\": \"sorprendido\",\n",
    "        \"üëâüèª\": \"se√±alando derecha\",\n",
    "        \"üí•\": \"explosi√≥n\",\n",
    "        \"üò¢\": \"llorando\",\n",
    "        \"ü¶ñ\": \"T-Rex\",\n",
    "        \"‚ö°\": \"rayo\",\n",
    "        \"üò¥\": \"durmiendo\",\n",
    "        \"ü´£\": \"espiando\",\n",
    "        \"üòª\": \"gato enamorado\",\n",
    "        \"ü•µ\": \"caliente\",\n",
    "        \"üëçüèª\": \"pulgar arriba\",\n",
    "        \"üáßüáæ\": \"Bielorrusia\",\n",
    "        \"ü§∑üèΩ‚Äç‚ôÄ\": \"mujer dudando\",\n",
    "        \"üòã\": \"saboreando\",\n",
    "        \"üö´\": \"prohibido\",\n",
    "        \"üëÖ\": \"lengua\",\n",
    "        \"üòÜ\": \"riendo mucho\",\n",
    "        \"üòä\": \"sonriendo feliz\",\n",
    "        \"üòá\": \"√°ngel\",\n",
    "        \"üò†\": \"enojado\",\n",
    "        \"üåé\": \"Am√©ricas\",\n",
    "        \"‚¨á\": \"bajar\",\n",
    "        \"üòû\": \"triste\",\n",
    "        \"üîµ\": \"c√≠rculo azul\",\n",
    "        \"üì®\": \"correo\",\n",
    "        \"üëÜ\": \"arriba\",\n",
    "        \"üòò\": \"besando\",\n",
    "        \"üåñ\": \"luna gibosa\",\n",
    "        \"‚ù§\": \"coraz√≥n rojo\",\n",
    "        \"‚òù\": \"dedo arriba\",\n",
    "        \"‚úå\": \"victoria\",\n",
    "        \"üçª\": \"brindis\",\n",
    "        \"ü§ù\": \"apret√≥n de manos\",\n",
    "        \"üëã\": \"saludo\",\n",
    "        \"üí≤\": \"d√≥lar\",\n",
    "        \"üëçüèº\": \"bien\",\n",
    "        \"üö∂üèª‚Äç‚ôÇ\": \"hombre caminando\",\n",
    "        \"ü§î\": \"pensando\",\n",
    "        \"üòπ\": \"gato riendo\",\n",
    "        \"ü´µ\": \"se√±alando\",\n",
    "        \"ü§≠\": \"riendo callado\",\n",
    "        \"ü™Ç\": \"paraca√≠das\",\n",
    "        \"üòà\": \"diablo\",\n",
    "        \"üî∞\": \"principiante\",\n",
    "        \"ü´Ä\": \"coraz√≥n\",\n",
    "        \"üòí\": \"molesto\",\n",
    "        \"ü§∑\": \"no s√©\",\n",
    "        \"üòÄ\": \"felicidad\",\n",
    "        \"üçÄ\": \"tr√©bol\",\n",
    "        \"üî™\": \"cuchillo\",\n",
    "        \"üòÆ\": \"boca abierta\",\n",
    "        \"üí¨\": \"hablar\",\n",
    "        \"‚úã\": \"mano levantada\",\n",
    "        \"üòå\": \"alivio\",\n",
    "        \"üí¶\": \"sudor\",\n",
    "        \"ü§∑üèº‚Äç‚ôÇ\": \"duda\",\n",
    "        \"‚òπ\": \"tristeza\",\n",
    "        \"ü§®\": \"sospecha\",\n",
    "        \"ü§ôüèΩ\": \"ll√°mame\",\n",
    "        \"üîª\": \"tri√°ngulo abajo\",\n",
    "        \"üõç\": \"compras\",\n",
    "        \"ü§ß\": \"estornudo\",\n",
    "        \"üí´\": \"mareo\",\n",
    "        \"üëº\": \"√°ngel\",\n",
    "        \"ü§å\": \"pellizco\",\n",
    "        \"üí®\": \"r√°pido\",\n",
    "        \"üòõ\": \"lengua fuera\",\n",
    "        \"üéÑ\": \"√°rbol de Navidad\",\n",
    "        \"ü•π\": \"l√°grimas contenidas\",\n",
    "        \"‚òÄ\": \"sol\",\n",
    "        \"üåï\": \"luna llena\",\n",
    "        \"üá∫üá∏\": \"Estados Unidos\",\n",
    "        \"üëèüèº\": \"aplausos\",\n",
    "        \"‚Äº\": \"doble exclamaci√≥n\",\n",
    "        \"üöÄ\": \"cohete\",\n",
    "        \"üò°\": \"furioso\",\n",
    "        \"üò¨\": \"nervios\",\n",
    "        \"üî¥\": \"c√≠rculo rojo\",\n",
    "        \"üôèüèª\": \"orando\",\n",
    "        \"üôà\": \"mono tap√°ndose\",\n",
    "        \"ü¶•\": \"perezoso\",\n",
    "        \"üåô\": \"luna creciente\",\n",
    "        \"üëà\": \"se√±alando izquierda\",\n",
    "        \"üê∑\": \"cerdo\",\n",
    "        \"ü•∏\": \"disfrazado\",\n",
    "        \"üòè\": \"sonrisa p√≠cara\",\n",
    "        \"üòö\": \"beso cerrado\",\n",
    "        \"‚öì\": \"ancla\",\n",
    "        \"üëå\": \"OK\",\n",
    "        \"ü§üüèª\": \"te amo\",\n",
    "        \"üåå\": \"v√≠a l√°ctea\",\n",
    "        \"‚ö†\": \"advertencia\",\n",
    "        \"ü•±\": \"bostezando\",\n",
    "        \"üê¨\": \"delf√≠n\",\n",
    "        \"üìä\": \"gr√°fico\",\n",
    "        \"üêÄ\": \"rata\",\n",
    "        \"ü§ó\": \"abrazo\",\n",
    "        \"üòî\": \"pensativo\",\n",
    "        \"üëèüèª\": \"aplaudiendo\",\n",
    "        \"üáßüá¨\": \"Bulgaria\",\n",
    "        \"ü•¥\": \"mareado\"\n",
    "    }\n",
    "    if emoji is None:\n",
    "        return emoji_map  # Tr·∫£ v·ªÅ to√†n b·ªô t·ª´ ƒëi·ªÉn n·∫øu kh√¥ng truy·ªÅn emoji\n",
    "    return emoji_map.get(emoji, emoji)  # Tr·∫£ v·ªÅ √°nh x·∫° ho·∫∑c emoji g·ªëc\n",
    "\n",
    "def replace_emojis_in_text(text):\n",
    "    result = text\n",
    "    for emoji, spanish_text in map_emoji_to_spanish().items():\n",
    "        result = result.replace(emoji, f\" {spanish_text} \")\n",
    "    words = result.split()\n",
    "    if not words:\n",
    "        return \"\"\n",
    "    cleaned_words = [words[0]]\n",
    "    for i in range(1, len(words)):\n",
    "        if words[i] != words[i-1]:\n",
    "            cleaned_words.append(words[i])\n",
    "    return \" \".join(cleaned_words).strip()\n",
    "\n",
    "for filename in os.listdir(data_dir):\n",
    "    if filename.endswith(\".json\"):\n",
    "        with open(os.path.join(data_dir, filename), \"r\") as f:\n",
    "            messages = json.load(f)\n",
    "            nick = filename.split(\".\")[0]\n",
    "            subjects[nick] = [\n",
    "                replace_emojis_in_text(str(msg[\"message\"]) if msg[\"message\"] is not None else \"\")\n",
    "                for msg in messages\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1744015989860,
     "user": {
      "displayName": "Ph√∫c Nguy·ªÖn Xu√¢n",
      "userId": "14670273794783355842"
     },
     "user_tz": -420
    },
    "id": "YIux-eMKafnG",
    "outputId": "ba8d66c8-f1f1-43b8-b9be-a245e18992f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Voy cargando la escopeta pa longuear alguna monedilla',\n",
       " 'Todav√≠a no',\n",
       " 'Esto est√° m√°s aburrido',\n",
       " 'Falta mucho para que entren los chinos ?',\n",
       " 'Por se√±ales de Facu ?',\n",
       " 'Compart√≠ ahora bien',\n",
       " 'Y compartilos ahora . Igual te van a banear cuando lean esto riendo',\n",
       " 'Sacate la papa de la boca',\n",
       " 'Se pic√≥ la clande',\n",
       " 'riendo',\n",
       " 'Screenshot ( 6 mar . 2022 20:03 : 38 )',\n",
       " 'La paciencia sudando',\n",
       " 'Divino ! aplaudiendo',\n",
       " 'Screenshot ( 6 mar . 2022 20:22 : 39 )',\n",
       " 'Cerrada lunitaa enamorado',\n",
       " 'mono tap√°ndose',\n",
       " 'Un short en 38k es lo mismo que ir al casino riendo',\n",
       " 'Recuperar que ?',\n",
       " 'Si no entra una ballena generosa en los pr√≥ximos minutos btc se pega un palo',\n",
       " 'Vamoooo ma√±ana se come enamorado',\n",
       " 'De proyectos no se absolutamente nada sonriendo feliz solo tradeo cualquier cosa que se mueva riendo',\n",
       " 'riendo aplaudiendo',\n",
       " '4 k en un trade ? Mierda ! Que haces ac√° hermano',\n",
       " 'Anoche no estaban meta long todos ?',\n",
       " 'Yo vi que subian longs a dos manos .. pero no recuerdo si era a anoche o el viernes',\n",
       " 'El miedo mueve m√°s que el fomo',\n",
       " 'Seguro . Esta semana m√°s tardar',\n",
       " 'Screenshot ( 7 mar . 2022 0:35 : 57 ) . Vamooooo que se comeeeee',\n",
       " 'Siguiendo a btc',\n",
       " 'Estaba long , cerr√© y ahora veremos si hice bien o me largo a llorar',\n",
       " 'Vamos lunita m√≠ amor',\n",
       " 'Yes',\n",
       " 'Dale Facu . Compra btc as√≠ pumpea riendo',\n",
       " 'Espero que suba mucho . Quiero platita',\n",
       " 'Hoy se come genial',\n",
       " 'Se comeeeeee genial',\n",
       " 'Seee . No toco m√°s nada hasta ma√±ana',\n",
       " 'Apag√≥ la compu para no cagarla riendo',\n",
       " 'riendo de una',\n",
       " 'Y ahora pabajoo sudando',\n",
       " 'Siempre sin ... Estoy cansado de ella mechazos',\n",
       " 'riendo',\n",
       " 'Cerrada genial',\n",
       " 'Hace a√±os que trabajo as√≠ . Prefiero el stop manual',\n",
       " 'En historial',\n",
       " 'Claro ... Son formas . No pongo stop peor estoy con el ojo en la pantalla cuando opero .',\n",
       " 'Ahhh si el porcentaje creo que no se puede . Solo con a operaci√≥n abierta',\n",
       " 'Ojal√° Bro',\n",
       " 'Acusalo con tu mam√° kikooo',\n",
       " 'Screenshot (8 mar . 2022 14:16 : 28 ) te amo biden enamorado',\n",
       " 'Gracia amigo',\n",
       " 'Yes . argento',\n",
       " 'Habl√≥ biden',\n",
       " 'Cerrado genial se come',\n",
       " 'El cierre o las entradas ?',\n",
       " 'Estabab todas en suporte y biden termin√≥ el discurso diciendo que no har√° nada con la guerra . Regaladas',\n",
       " 'Gracias Bro',\n",
       " 'Parece que no piensa retroceder hombre encogi√©ndose habr√° que esperar',\n",
       " 'Todo el d√≠a haciendo Plata y en esta sub√≠a no met√≠ ni un long riendo fuerte riendo fuerte riendo fuerte',\n",
       " 'Btc mete liquidaciones a la baja y luego cohete',\n",
       " 'Primero deber√≠a buscar los 42600 . Si rompe , a los 44000',\n",
       " 'Cu√°l tri√°ngulo ?',\n",
       " 'Lunita se paga el asado enamorado',\n",
       " 'Si , Justo ah√≠ Por qu√© est√° a pr√≥xima a la l√≠nea de tendencia que hab√≠a roto . Y no me anim√© a long',\n",
       " 'Se comeeeeeeee genial',\n",
       " 'Hoy se comi√≥ gracias a powel',\n",
       " 'user 9092 - London capital group',\n",
       " 'Se come genial',\n",
       " 'Ma√±ana se come asado',\n",
       " 'Comparto m√≠ felicidad como el grupo . C√≥mo hacen todos sorprendido',\n",
       " 'Ya dijo',\n",
       " 'Justo estaba por cerrar las operaciones furioso',\n",
       " 'Yo no',\n",
       " 'Rezar',\n",
       " 'Depende directamente de la tendencia ... En tendencia bajista te user 15930 m√°s resultados los shorts y viceversa',\n",
       " 'Buenas gente . Alguien de ac√° utiliza paxuful ?',\n",
       " 'Paxful era . Jaja',\n",
       " 'Buenas gente . Una pregunta bien de ignorante . Alguien de ac√° utiliz√≥ el bono de bienvenida de huobi ? Es real eso ? Es tan f√°cil como dicen ?',\n",
       " 'Ah ... Que truchada',\n",
       " 'Sobrevivir',\n",
       " 'Claro . Depende donde y que tipo de vida . Yo con 300 al mes muero de angustia',\n",
       " 'Ni a palos . Cunado compraste pan por √∫ltima vez ?',\n",
       " 'Ac√° en m√≠ barrio 300 para arriba',\n",
       " 'No s√© d√≥nde viven ustedes o que comen . Pero yo ac√° en zona norte de BS AS . Con 300 dolares por mes solo me alcanza para comer . Y ah√≠ ajustado',\n",
       " 'Tus hijos no ser√°n compa√±eros de los m√≠os no ? riendo Ami con 300 tampoco llego a pagar el cole',\n",
       " '20 por d√≠as no est√° mal . Pero solo para comer y hasta ahi']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjects['user10343']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 319,
     "status": "ok",
     "timestamp": 1744013467217,
     "user": {
      "displayName": "Ph√∫c Nguy·ªÖn Xu√¢n",
      "userId": "14670273794783355842"
     },
     "user_tz": -420
    },
    "id": "PKbYkJtcgk9_",
    "outputId": "ae8b4ec7-7065-4fea-ce35-fa7cb356b488"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T·ªïng s·ªë m·∫´u: 528, Ph√¢n b·ªë nh√£n: [356 172]\n"
     ]
    }
   ],
   "source": [
    "task1_labels = {}\n",
    "with open(\"data/task1/train/gold_task1.txt\", \"r\") as f:\n",
    "    next(f)\n",
    "    for line in f:\n",
    "        nick, risk = line.strip().split(\",\")\n",
    "        task1_labels[nick] = int(risk)\n",
    "\n",
    "messages = []\n",
    "labels = []\n",
    "for nick, subject_messages in subjects.items():\n",
    "    if nick in task1_labels:\n",
    "        if task1_labels[nick] == 0:\n",
    "            msg_len = len(subject_messages)\n",
    "            if msg_len > 1:\n",
    "                split_point = msg_len // 2\n",
    "                messages.append(subject_messages[:split_point])\n",
    "                messages.append(subject_messages[split_point:])\n",
    "                labels.extend([0, 0])\n",
    "            else:\n",
    "                messages.append(subject_messages)\n",
    "                labels.append(0)\n",
    "        else:\n",
    "            messages.append(subject_messages)\n",
    "            labels.append(task1_labels[nick])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1744013414938,
     "user": {
      "displayName": "Ph√∫c Nguy·ªÖn Xu√¢n",
      "userId": "14670273794783355842"
     },
     "user_tz": -420
    },
    "id": "ZhnnZf4yPh4d"
   },
   "outputs": [],
   "source": [
    "class EmbDataset(Dataset):\n",
    "    def __init__(self, embeddings, labels):\n",
    "        self.embeddings = embeddings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.embeddings[idx], self.labels[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1744013415750,
     "user": {
      "displayName": "Ph√∫c Nguy·ªÖn Xu√¢n",
      "userId": "14670273794783355842"
     },
     "user_tz": -420
    },
    "id": "Pyr0l8M8Pw2h"
   },
   "outputs": [],
   "source": [
    "class EmbDatasetRNNAug(Dataset):\n",
    "    def __init__(self, embeddings, labels, thr_rng=0.7, n_msg=10):\n",
    "        self.embeddings = embeddings\n",
    "        self.labels = labels\n",
    "        self.emb0 = [embeddings[i] for i in range(len(labels)) if labels[i] == 0]\n",
    "        self.thr_rng = thr_rng\n",
    "        self.n_msg = n_msg\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.labels[idx] == 0:\n",
    "            nr_msg = np.random.randint(1, len(self.embeddings[idx]) + 1)\n",
    "            return self.embeddings[idx][:nr_msg], self.labels[idx]\n",
    "        else:\n",
    "            rnd = np.random.uniform()\n",
    "            if rnd > self.thr_rng:\n",
    "                neutral = self.emb0[np.random.randint(0, len(self.emb0))]\n",
    "                n_extra = np.random.randint(1, min(len(neutral), self.n_msg))\n",
    "                return np.concatenate([neutral[:n_extra], self.embeddings[idx]], axis=0), self.labels[idx]\n",
    "            return self.embeddings[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1744013417276,
     "user": {
      "displayName": "Ph√∫c Nguy·ªÖn Xu√¢n",
      "userId": "14670273794783355842"
     },
     "user_tz": -420
    },
    "id": "2pt2oMhJxVbI"
   },
   "outputs": [],
   "source": [
    "def make_plot(train_scores, val_scores, y_label, figsize=(8,5)):\n",
    "    fig, ax = plt.subplots(1,1,figsize=figsize)\n",
    "    ax.plot(train_scores, label='Train')\n",
    "    ax.plot(val_scores, label='Val')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel(y_label)\n",
    "    ax.legend()\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1744013418401,
     "user": {
      "displayName": "Ph√∫c Nguy·ªÖn Xu√¢n",
      "userId": "14670273794783355842"
     },
     "user_tz": -420
    },
    "id": "t_uyzb9n5bnZ"
   },
   "outputs": [],
   "source": [
    "def get_cls_embeddings(all_messages, model, tokenizer, device, m_length=96):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for subject_messages in tqdm(all_messages):\n",
    "            input = tokenizer(subject_messages, padding=True, truncation=True, max_length=m_length, return_tensors='pt')\n",
    "            output = model(**input.to(device))\n",
    "            embeddings.append(output.last_hidden_state[:, 0, :].cpu().numpy())\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1744015975200,
     "user": {
      "displayName": "Ph√∫c Nguy·ªÖn Xu√¢n",
      "userId": "14670273794783355842"
     },
     "user_tz": -420
    },
    "id": "dt62Oejy7HvO"
   },
   "outputs": [],
   "source": [
    "def lstm_collate(batch):\n",
    "    labels = [x[1] for x in batch]\n",
    "    labels = torch.tensor(labels, dtype=torch.long)\n",
    "    data = [torch.tensor(x[0], dtype=torch.float32) for x in batch]\n",
    "    batch_data = pad_sequence(data)\n",
    "    lens = torch.tensor([len(x) for x in data], dtype=torch.long).unsqueeze(0).unsqueeze(-1)\n",
    "    lens -= 1\n",
    "    return batch_data, lens, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1744015995746,
     "user": {
      "displayName": "Ph√∫c Nguy·ªÖn Xu√¢n",
      "userId": "14670273794783355842"
     },
     "user_tz": -420
    },
    "id": "JXy8u0t8Ugo7"
   },
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_size, h_size, output_dim, dropout=0):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size, h_size, num_layers=1, batch_first=False, dropout=dropout, bidirectional=True)\n",
    "        self.attention = nn.Linear(2 * h_size, 1)\n",
    "        self.classifier = nn.Linear(2 * h_size, output_dim)\n",
    "\n",
    "    def forward(self, seq_data, seq_lens, state=None):\n",
    "        lstm_out, _ = self.lstm(seq_data)\n",
    "        attention_weights = torch.softmax(self.attention(lstm_out), dim=0)\n",
    "        context_vector = torch.sum(attention_weights * lstm_out, dim=0)\n",
    "        return self.classifier(context_vector)\n",
    "\n",
    "    def predict_all_timesteps(self, seq_data, seq_lens, state=None):\n",
    "        lstm_out, _ = self.lstm(seq_data)\n",
    "        attention_weights = torch.softmax(self.attention(lstm_out), dim=0)\n",
    "        logits_all = self.classifier(lstm_out)\n",
    "        pred_all = torch.argmax(logits_all, dim=2)\n",
    "        ts_predictions = [pred_all[:seq_lens[0, i].item(), i].squeeze().cpu().numpy() for i in range(pred_all.shape[1])]\n",
    "        return ts_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 52694,
     "status": "ok",
     "timestamp": 1744013522812,
     "user": {
      "displayName": "Ph√∫c Nguy·ªÖn Xu√¢n",
      "userId": "14670273794783355842"
     },
     "user_tz": -420
    },
    "id": "iXD3RXb6c_TR",
    "outputId": "a0e1d29e-6894-4fcf-b480-c8bfcd56d713"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at pysentimiento/robertuito-sentiment-analysis and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 528/528 [00:31<00:00, 16.93it/s]\n"
     ]
    }
   ],
   "source": [
    "# Thi·∫øt l·∫≠p v√† hu·∫•n luy·ªán\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "name = 'pysentimiento/robertuito-sentiment-analysis'\n",
    "tokenizer = AutoTokenizer.from_pretrained(name)\n",
    "model = AutoModel.from_pretrained(name)\n",
    "embs = get_cls_embeddings(messages, model, tokenizer, device, m_length=96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 886
    },
    "executionInfo": {
     "elapsed": 169504,
     "status": "error",
     "timestamp": 1744019650631,
     "user": {
      "displayName": "Ph√∫c Nguy·ªÖn Xu√¢n",
      "userId": "14670273794783355842"
     },
     "user_tz": -420
    },
    "id": "ZVWsx0ZnhKfh",
    "outputId": "7ff975f2-9060-4a73-acb4-2764da59ad4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ph√¢n b·ªë nh√£n trong t·∫≠p train:\n",
      "[282 278]\n",
      "Ph√¢n b·ªë nh√£n trong t·∫≠p test:\n",
      "[74 66]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [03:06<00:00,  1.24s/it, loss=0.1489, val_f1=0.9569]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== K·∫øt qu·∫£ cho h_size: 96, batch_size: 2 ===\u001b[0m\n",
      "+---------------------+--------+\n",
      "| Metric              |  Value |\n",
      "+---------------------+--------+\n",
      "| Epoch t·ªët nh·∫•t      |    117 |\n",
      "| Val Macro F1        | 0.9713 |\n",
      "| Train_eval Macro F1 | 0.9982 |\n",
      "+---------------------+--------+\n",
      "\n",
      "\u001b[32mValidation Set:\u001b[0m\n",
      "           Pred 0   Pred 1\n",
      "  True 0       72        2\n",
      "  True 1        2       64\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        74\n",
      "           1       0.97      0.97      0.97        66\n",
      "\n",
      "    accuracy                           0.97       140\n",
      "   macro avg       0.97      0.97      0.97       140\n",
      "weighted avg       0.97      0.97      0.97       140\n",
      "\n",
      "\n",
      "\u001b[33mTrain_eval Set:\u001b[0m\n",
      "           Pred 0   Pred 1\n",
      "  True 0       72        2\n",
      "  True 1        4       62\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       282\n",
      "           1       1.00      1.00      1.00       278\n",
      "\n",
      "    accuracy                           1.00       560\n",
      "   macro avg       1.00      1.00      1.00       560\n",
      "weighted avg       1.00      1.00      1.00       560\n",
      "\n",
      "\u001b[36m==================================================\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [01:53<00:00,  1.32it/s, loss=0.1862, val_f1=0.9353]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== K·∫øt qu·∫£ cho h_size: 96, batch_size: 4 ===\u001b[0m\n",
      "+---------------------+--------+\n",
      "| Metric              |  Value |\n",
      "+---------------------+--------+\n",
      "| Epoch t·ªët nh·∫•t      |    142 |\n",
      "| Val Macro F1        | 0.9498 |\n",
      "| Train_eval Macro F1 | 1.0000 |\n",
      "+---------------------+--------+\n",
      "\n",
      "\u001b[32mValidation Set:\u001b[0m\n",
      "           Pred 0   Pred 1\n",
      "  True 0       71        3\n",
      "  True 1        4       62\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95        74\n",
      "           1       0.95      0.94      0.95        66\n",
      "\n",
      "    accuracy                           0.95       140\n",
      "   macro avg       0.95      0.95      0.95       140\n",
      "weighted avg       0.95      0.95      0.95       140\n",
      "\n",
      "\n",
      "\u001b[33mTrain_eval Set:\u001b[0m\n",
      "           Pred 0   Pred 1\n",
      "  True 0       71        3\n",
      "  True 1        6       60\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       282\n",
      "           1       1.00      1.00      1.00       278\n",
      "\n",
      "    accuracy                           1.00       560\n",
      "   macro avg       1.00      1.00      1.00       560\n",
      "weighted avg       1.00      1.00      1.00       560\n",
      "\n",
      "\u001b[36m==================================================\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [01:05<00:00,  2.30it/s, loss=0.1989, val_f1=0.8049]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== K·∫øt qu·∫£ cho h_size: 96, batch_size: 8 ===\u001b[0m\n",
      "+---------------------+--------+\n",
      "| Metric              |  Value |\n",
      "+---------------------+--------+\n",
      "| Epoch t·ªët nh·∫•t      |     49 |\n",
      "| Val Macro F1        | 0.9000 |\n",
      "| Train_eval Macro F1 | 0.9821 |\n",
      "+---------------------+--------+\n",
      "\n",
      "\u001b[32mValidation Set:\u001b[0m\n",
      "           Pred 0   Pred 1\n",
      "  True 0       62       12\n",
      "  True 1        2       64\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.84      0.90        74\n",
      "           1       0.84      0.97      0.90        66\n",
      "\n",
      "    accuracy                           0.90       140\n",
      "   macro avg       0.91      0.90      0.90       140\n",
      "weighted avg       0.91      0.90      0.90       140\n",
      "\n",
      "\n",
      "\u001b[33mTrain_eval Set:\u001b[0m\n",
      "           Pred 0   Pred 1\n",
      "  True 0       49       25\n",
      "  True 1        2       64\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98       282\n",
      "           1       0.97      1.00      0.98       278\n",
      "\n",
      "    accuracy                           0.98       560\n",
      "   macro avg       0.98      0.98      0.98       560\n",
      "weighted avg       0.98      0.98      0.98       560\n",
      "\n",
      "\u001b[36m==================================================\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [03:45<00:00,  1.51s/it, loss=0.1474, val_f1=0.9071]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== K·∫øt qu·∫£ cho h_size: 128, batch_size: 2 ===\u001b[0m\n",
      "+---------------------+--------+\n",
      "| Metric              |  Value |\n",
      "+---------------------+--------+\n",
      "| Epoch t·ªët nh·∫•t      |     68 |\n",
      "| Val Macro F1        | 0.9569 |\n",
      "| Train_eval Macro F1 | 1.0000 |\n",
      "+---------------------+--------+\n",
      "\n",
      "\u001b[32mValidation Set:\u001b[0m\n",
      "           Pred 0   Pred 1\n",
      "  True 0       72        2\n",
      "  True 1        4       62\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96        74\n",
      "           1       0.97      0.94      0.95        66\n",
      "\n",
      "    accuracy                           0.96       140\n",
      "   macro avg       0.96      0.96      0.96       140\n",
      "weighted avg       0.96      0.96      0.96       140\n",
      "\n",
      "\n",
      "\u001b[33mTrain_eval Set:\u001b[0m\n",
      "           Pred 0   Pred 1\n",
      "  True 0       65        9\n",
      "  True 1        4       62\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       282\n",
      "           1       1.00      1.00      1.00       278\n",
      "\n",
      "    accuracy                           1.00       560\n",
      "   macro avg       1.00      1.00      1.00       560\n",
      "weighted avg       1.00      1.00      1.00       560\n",
      "\n",
      "\u001b[36m==================================================\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [02:29<00:00,  1.00it/s, loss=0.1878, val_f1=0.9284]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== K·∫øt qu·∫£ cho h_size: 128, batch_size: 4 ===\u001b[0m\n",
      "+---------------------+--------+\n",
      "| Metric              |  Value |\n",
      "+---------------------+--------+\n",
      "| Epoch t·ªët nh·∫•t      |    130 |\n",
      "| Val Macro F1        | 0.9569 |\n",
      "| Train_eval Macro F1 | 1.0000 |\n",
      "+---------------------+--------+\n",
      "\n",
      "\u001b[32mValidation Set:\u001b[0m\n",
      "           Pred 0   Pred 1\n",
      "  True 0       72        2\n",
      "  True 1        4       62\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96        74\n",
      "           1       0.97      0.94      0.95        66\n",
      "\n",
      "    accuracy                           0.96       140\n",
      "   macro avg       0.96      0.96      0.96       140\n",
      "weighted avg       0.96      0.96      0.96       140\n",
      "\n",
      "\n",
      "\u001b[33mTrain_eval Set:\u001b[0m\n",
      "           Pred 0   Pred 1\n",
      "  True 0       68        6\n",
      "  True 1        4       62\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       282\n",
      "           1       1.00      1.00      1.00       278\n",
      "\n",
      "    accuracy                           1.00       560\n",
      "   macro avg       1.00      1.00      1.00       560\n",
      "weighted avg       1.00      1.00      1.00       560\n",
      "\n",
      "\u001b[36m==================================================\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [01:51<00:00,  1.35it/s, loss=0.1958, val_f1=0.8712]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== K·∫øt qu·∫£ cho h_size: 128, batch_size: 8 ===\u001b[0m\n",
      "+---------------------+--------+\n",
      "| Metric              |  Value |\n",
      "+---------------------+--------+\n",
      "| Epoch t·ªët nh·∫•t      |     30 |\n",
      "| Val Macro F1        | 0.9071 |\n",
      "| Train_eval Macro F1 | 0.9929 |\n",
      "+---------------------+--------+\n",
      "\n",
      "\u001b[32mValidation Set:\u001b[0m\n",
      "           Pred 0   Pred 1\n",
      "  True 0       65        9\n",
      "  True 1        4       62\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.88      0.91        74\n",
      "           1       0.87      0.94      0.91        66\n",
      "\n",
      "    accuracy                           0.91       140\n",
      "   macro avg       0.91      0.91      0.91       140\n",
      "weighted avg       0.91      0.91      0.91       140\n",
      "\n",
      "\n",
      "\u001b[33mTrain_eval Set:\u001b[0m\n",
      "           Pred 0   Pred 1\n",
      "  True 0       58       16\n",
      "  True 1        2       64\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       282\n",
      "           1       0.99      0.99      0.99       278\n",
      "\n",
      "    accuracy                           0.99       560\n",
      "   macro avg       0.99      0.99      0.99       560\n",
      "weighted avg       0.99      0.99      0.99       560\n",
      "\n",
      "\u001b[36m==================================================\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def validate_tms_rnn(subject_embs, labels, net, device):\n",
    "    net.to(device)\n",
    "    net.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        batch_data, batch_lens, _ = lstm_collate([(embs, label) for embs, label in zip(subject_embs, labels)])\n",
    "        batch_data, batch_lens = batch_data.to(device), batch_lens.to(device)\n",
    "        seq_predictions = net.predict_all_timesteps(batch_data, batch_lens)\n",
    "        for seq_pred, true_label in zip(seq_predictions, labels):\n",
    "            idxs = np.nonzero(seq_pred)[0]\n",
    "            predictions.append(seq_pred[idxs[0]] if len(idxs) > 0 else 0)\n",
    "    return {\n",
    "        'acc': metrics.accuracy_score(labels, predictions),\n",
    "        'macro_f1': metrics.f1_score(labels, predictions, average='macro', zero_division=0),\n",
    "        'cls_report': metrics.classification_report(labels, predictions, zero_division=0),\n",
    "        'cfm': metrics.confusion_matrix(labels, predictions)\n",
    "    }\n",
    "def train_gdro_rnn_sl(net, optimizer, device, criterion, train_dl, q, soft_labels, eta=0.1):\n",
    "    net.to(device)\n",
    "    net.train()\n",
    "    loss = 0\n",
    "    num_batches = 0\n",
    "    preds = []\n",
    "    labels = []\n",
    "    for batch_data, batch_lens, batch_labels in train_dl:\n",
    "        labels.append(batch_labels.numpy())\n",
    "        unique_batch_labels = np.unique(batch_labels.numpy())\n",
    "        batch_data, batch_labels = batch_data.to(device), batch_labels.to(device)\n",
    "        batch_lens = batch_lens.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = net(batch_data, batch_lens)\n",
    "        batch_losses = nn.functional.cross_entropy(out, soft_labels[batch_labels], reduction='none')\n",
    "        for cls in unique_batch_labels:\n",
    "            idx_cls = batch_labels == cls\n",
    "            q[cls] *= (eta * batch_losses[idx_cls].mean()).exp().item()\n",
    "        q /= q.sum()\n",
    "        loss_value = sum(q[cls] * batch_losses[batch_labels == cls].mean() for cls in unique_batch_labels)\n",
    "        loss_value.backward()\n",
    "        optimizer.step()\n",
    "        loss += loss_value.item()\n",
    "        num_batches += 1\n",
    "        preds.append(torch.argmax(out, axis=-1).cpu().numpy())\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "    preds = np.concatenate(preds, axis=0)\n",
    "    return {\n",
    "        'loss': loss / num_batches,\n",
    "        'acc': metrics.accuracy_score(labels, preds),\n",
    "        'macro_f1': metrics.f1_score(labels, preds, average='macro', zero_division=0),\n",
    "        'cls_report': metrics.classification_report(labels, preds, zero_division=0),\n",
    "        'cfm': metrics.confusion_matrix(labels, preds)\n",
    "    }, q\n",
    "\n",
    "def run_train_gdro_rnn_sl(net, optimizer, criterion, device, train_dl, train_embs, train_labels,\n",
    "                          val_embs, val_labels, soft_labels, output_dir, max_epochs=150, n_classes=2, eta=0.1):\n",
    "    best_macro_f1_val = 0\n",
    "    logs = {'train': defaultdict(list), 'val': defaultdict(list), 'train_eval': defaultdict(list), 'epoch': 0}\n",
    "    q = torch.ones(n_classes, dtype=torch.float32, device=device) / n_classes\n",
    "    with tqdm(total=max_epochs, desc=\"Training\", bar_format=\"{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}{postfix}]\") as pbar:\n",
    "        for epoch in range(max_epochs):\n",
    "            train_report, q = train_gdro_rnn_sl(net, optimizer, device, criterion, train_dl, q, soft_labels, eta)\n",
    "            logs['train'].update({k: logs['train'][k] + [v] for k, v in train_report.items()})\n",
    "            val_report = validate_tms_rnn(val_embs, val_labels, net, device)\n",
    "            logs['val'].update({k: logs['val'][k] + [v] for k, v in val_report.items()})\n",
    "            pbar.set_postfix({'loss': f\"{train_report['loss']:.4f}\", 'val_f1': f\"{val_report['macro_f1']:.4f}\"})\n",
    "            pbar.update(1)\n",
    "            if val_report['macro_f1'] >= best_macro_f1_val:\n",
    "                best_macro_f1_val = val_report['macro_f1']\n",
    "                torch.save(net.cpu().state_dict(), f'{output_dir}/net_params.pt')\n",
    "                logs['epoch'] = epoch\n",
    "                train_report_eval = validate_tms_rnn(train_embs, train_labels, net, device)\n",
    "                logs['train_eval'].update({k: logs['train_eval'][k] + [v] for k, v in train_report_eval.items()})\n",
    "    return logs\n",
    "\n",
    "def format_confusion_matrix(cfm):\n",
    "    return \"\\n\".join([\n",
    "        f\"{'':>8} {'Pred 0':>8} {'Pred 1':>8}\",\n",
    "        f\"{'True 0':>8} {cfm[0,0]:8d} {cfm[0,1]:8d}\",\n",
    "        f\"{'True 1':>8} {cfm[1,0]:8d} {cfm[1,1]:8d}\"\n",
    "    ])\n",
    "\n",
    "ds = EmbDatasetRNNAug(embs, labels, thr_rng=0.6, n_msg=10)\n",
    "train_ds, test_ds = random_split(ds, [0.8, 0.2], generator=torch.Generator().manual_seed(2909))\n",
    "train_labels = [labels[i] for i in train_ds.indices]\n",
    "test_labels = [labels[i] for i in test_ds.indices]\n",
    "val_embs = [embs[i] for i in test_ds.indices]\n",
    "val_labels = [labels[i] for i in test_ds.indices]\n",
    "train_embs = [embs[i] for i in train_ds.indices]\n",
    "train_labels = [labels[i] for i in train_ds.indices]\n",
    "\n",
    "save_dir = 'pre_trained_models'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "soft_labels = torch.tensor([[0.95, 0.05], [0.05, 0.95]], dtype=torch.float32, device=device)\n",
    "\n",
    "f1s = []\n",
    "for h_size in [96, 128]:\n",
    "    scores = []\n",
    "    for bs in [2, 4, 8]:\n",
    "        dir_name = f'processed_data_h_{h_size}_bs_{bs}_0.95_0.05'\n",
    "        output_dir = os.path.join(save_dir, dir_name)\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        random.seed(2909)\n",
    "        np.random.seed(2909)\n",
    "        torch.manual_seed(2909)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "        train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True, drop_last=False, collate_fn=lstm_collate)\n",
    "        net = LSTMClassifier(embs[0].shape[-1], h_size=h_size, output_dim=2)\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=1e-4)\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "        logs = run_train_gdro_rnn_sl(net, optimizer, loss_fn, device, train_dl, train_embs, train_labels,\n",
    "                                     val_embs, val_labels, soft_labels, output_dir, max_epochs=150)\n",
    "\n",
    "        for k in logs['train_eval']:\n",
    "            if k not in ['cls_report', 'cfm']:\n",
    "                fig, ax = make_plot(logs['train'][k], logs['val'][k], k)\n",
    "                fig.savefig(f'{output_dir}/{k}.png')\n",
    "                plt.close(fig)\n",
    "                fig, ax = make_plot(logs['train_eval'][k], logs['val'][k], k)\n",
    "                fig.savefig(f'{output_dir}/{k}_eval.png')\n",
    "                plt.close(fig)\n",
    "\n",
    "        np.save(f'{output_dir}/logs.npy', logs, allow_pickle=True)\n",
    "\n",
    "        arg = np.argmax(logs['val']['macro_f1'])\n",
    "        table_data = [\n",
    "            [\"Epoch t·ªët nh·∫•t\", arg],\n",
    "            [\"Val Macro F1\", f\"{logs['val']['macro_f1'][arg]:.4f}\"],\n",
    "            [\"Train_eval Macro F1\", f\"{logs['train_eval']['macro_f1'][-1]:.4f}\"]\n",
    "        ]\n",
    "        print(f\"{Fore.CYAN}=== K·∫øt qu·∫£ cho h_size: {h_size}, batch_size: {bs} ==={Style.RESET_ALL}\")\n",
    "        print(tabulate(table_data, headers=[\"Metric\", \"Value\"], tablefmt=\"pretty\", colalign=(\"left\", \"right\")))\n",
    "        print(f\"\\n{Fore.GREEN}Validation Set:{Style.RESET_ALL}\")\n",
    "        print(format_confusion_matrix(logs['val']['cfm'][arg]))\n",
    "        print(f\"\\n{logs['val']['cls_report'][arg]}\")\n",
    "        print(f\"\\n{Fore.YELLOW}Train_eval Set:{Style.RESET_ALL}\")\n",
    "        print(format_confusion_matrix(logs['val']['cfm'][-1]))\n",
    "        print(f\"\\n{logs['train_eval']['cls_report'][-1]}\")\n",
    "        print(f\"{Fore.CYAN}{'='*50}{Style.RESET_ALL}\\n\")\n",
    "        scores.append(logs['val']['macro_f1'][arg])\n",
    "    f1s.append(scores)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "MentalRisk2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
