{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 35972,
     "status": "ok",
     "timestamp": 1744013153366,
     "user": {
      "displayName": "Phúc Nguyễn Xuân",
      "userId": "14670273794783355842"
     },
     "user_tz": -420
    },
    "id": "NfcR90bVFpFK"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import emoji\n",
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from tabulate import tabulate\n",
    "from colorama import init, Fore, Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UqC7SVG3Vi0r"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tất cả các biểu tượng cảm xúc trong dữ liệu:\n",
      "🫀 - :anatomical_heart:\n",
      "😱 - :face_screaming_in_fear:\n",
      "🇮🇳 - :India:\n",
      "🎉 - :party_popper:\n",
      "🐬 - :dolphin:\n",
      "🥳 - :partying_face:\n",
      "😉 - :winking_face:\n",
      "⛔ - :no_entry:\n",
      "🚀 - :rocket:\n",
      "😶 - :face_without_mouth:\n",
      "👌🏼 - :OK_hand_medium-light_skin_tone:\n",
      "👆 - :backhand_index_pointing_up:\n",
      "😠 - :angry_face:\n",
      "🌚 - :new_moon_face:\n",
      "😕 - :confused_face:\n",
      "🤦🏻‍♂ - :man_facepalming_light_skin_tone:\n",
      "👆🏽 - :backhand_index_pointing_up_medium_skin_tone:\n",
      "🐻 - :bear:\n",
      "😴 - :sleeping_face:\n",
      "💶 - :euro_banknote:\n",
      "😔 - :pensive_face:\n",
      "🙈 - :see-no-evil_monkey:\n",
      "🥺 - :pleading_face:\n",
      "😪 - :sleepy_face:\n",
      "🦖 - :T-Rex:\n",
      "💰 - :money_bag:\n",
      "🥚 - :egg:\n",
      "🍎 - :red_apple:\n",
      "✅ - :check_mark_button:\n",
      "😮 - :face_with_open_mouth:\n",
      "☹ - :frowning_face:\n",
      "👏 - :clapping_hands:\n",
      "♥ - :heart_suit:\n",
      "😨 - :fearful_face:\n",
      "🤦🏻‍♀ - :woman_facepalming_light_skin_tone:\n",
      "🔪 - :kitchen_knife:\n",
      "❗ - :red_exclamation_mark:\n",
      "🐮 - :cow_face:\n",
      "🎈 - :balloon:\n",
      "📊 - :bar_chart:\n",
      "👏🏻 - :clapping_hands_light_skin_tone:\n",
      "📈 - :chart_increasing:\n",
      "🟣 - :purple_circle:\n",
      "😳 - :flushed_face:\n",
      "😁 - :beaming_face_with_smiling_eyes:\n",
      "🐳 - :spouting_whale:\n",
      "👼 - :baby_angel:\n",
      "🍏 - :green_apple:\n",
      "🔝 - :TOP_arrow:\n",
      "🤙 - :call_me_hand:\n",
      "🚶🏻‍♂ - :man_walking_light_skin_tone:\n",
      "🤨 - :face_with_raised_eyebrow:\n",
      "💪 - :flexed_biceps:\n",
      "👉 - :backhand_index_pointing_right:\n",
      "🤦‍♂ - :man_facepalming:\n",
      "🫵 - :index_pointing_at_the_viewer:\n",
      "🌊 - :water_wave:\n",
      "🥰 - :smiling_face_with_hearts:\n",
      "🤑 - :money-mouth_face:\n",
      "😓 - :downcast_face_with_sweat:\n",
      "🐟 - :fish:\n",
      "🎄 - :Christmas_tree:\n",
      "🔴 - :red_circle:\n",
      "🇺🇦 - :Ukraine:\n",
      "🇺🇸 - :United_States:\n",
      "💋 - :kiss_mark:\n",
      "✌ - :victory_hand:\n",
      "⬆ - :up_arrow:\n",
      "😲 - :astonished_face:\n",
      "3️⃣ - :keycap_3:\n",
      "💩 - :pile_of_poo:\n",
      "😒 - :unamused_face:\n",
      "😶‍🌫 - :face_in_clouds:\n",
      "🇧🇬 - :Bulgaria:\n",
      "✌🏽 - :victory_hand_medium_skin_tone:\n",
      "🤷🏻‍♂ - :man_shrugging_light_skin_tone:\n",
      "🇦🇷 - :Argentina:\n",
      "🇳🇬 - :Nigeria:\n",
      "👍🏾 - :thumbs_up_medium-dark_skin_tone:\n",
      "🙄 - :face_with_rolling_eyes:\n",
      "🎾 - :tennis:\n",
      "😏 - :smirking_face:\n",
      "🇪🇸 - :Spain:\n",
      "🙏🏻 - :folded_hands_light_skin_tone:\n",
      "☀ - :sun:\n",
      "🍺 - :beer_mug:\n",
      "👍 - :thumbs_up:\n",
      "🥹 - :face_holding_back_tears:\n",
      "🧐 - :face_with_monocle:\n",
      "🖐🏽 - :hand_with_fingers_splayed_medium_skin_tone:\n",
      "☝🏻 - :index_pointing_up_light_skin_tone:\n",
      "🎶 - :musical_notes:\n",
      "🤝 - :handshake:\n",
      "🤣 - :rolling_on_the_floor_laughing:\n",
      "🙋🏻‍♀ - :woman_raising_hand_light_skin_tone:\n",
      "😅 - :grinning_face_with_sweat:\n",
      "⚰ - :coffin:\n",
      "1️⃣ - :keycap_1:\n",
      "🫤 - :face_with_diagonal_mouth:\n",
      "🙀 - :weary_cat:\n",
      "🙂 - :slightly_smiling_face:\n",
      "🪜 - :ladder:\n",
      "🤧 - :sneezing_face:\n",
      "🤷🏽‍♀ - :woman_shrugging_medium_skin_tone:\n",
      "😥 - :sad_but_relieved_face:\n",
      "😯 - :hushed_face:\n",
      "💃 - :woman_dancing:\n",
      "🔥 - :fire:\n",
      "💪🏼 - :flexed_biceps_medium-light_skin_tone:\n",
      "4️⃣ - :keycap_4:\n",
      "🔻 - :red_triangle_pointed_down:\n",
      "🤮 - :face_vomiting:\n",
      "😆 - :grinning_squinting_face:\n",
      "🤔 - :thinking_face:\n",
      "🛍 - :shopping_bags:\n",
      "✌🏻 - :victory_hand_light_skin_tone:\n",
      "🤌 - :pinched_fingers:\n",
      "😑 - :expressionless_face:\n",
      "😊 - :smiling_face_with_smiling_eyes:\n",
      "⚠ - :warning:\n",
      "🤷 - :person_shrugging:\n",
      "🙌 - :raising_hands:\n",
      "⏺ - :record_button:\n",
      "🎂 - :birthday_cake:\n",
      "👋 - :waving_hand:\n",
      "🙌🏽 - :raising_hands_medium_skin_tone:\n",
      "🔵 - :blue_circle:\n",
      "🤷🏼‍♂ - :man_shrugging_medium-light_skin_tone:\n",
      "🖐🏼 - :hand_with_fingers_splayed_medium-light_skin_tone:\n",
      "🌬 - :wind_face:\n",
      "❌ - :cross_mark:\n",
      "❣ - :heart_exclamation:\n",
      "👌🏽 - :OK_hand_medium_skin_tone:\n",
      "‼ - :double_exclamation_mark:\n",
      "🤓 - :nerd_face:\n",
      "👁 - :eye:\n",
      "🍀 - :four_leaf_clover:\n",
      "👏🏼 - :clapping_hands_medium-light_skin_tone:\n",
      "🎵 - :musical_note:\n",
      "🙏 - :folded_hands:\n",
      "🤦🏽‍♂ - :man_facepalming_medium_skin_tone:\n",
      "🦥 - :sloth:\n",
      "🎁 - :wrapped_gift:\n",
      "💲 - :heavy_dollar_sign:\n",
      "😻 - :smiling_cat_with_heart-eyes:\n",
      "😵‍💫 - :face_with_spiral_eyes:\n",
      "🧘🏻‍♂ - :man_in_lotus_position_light_skin_tone:\n",
      "🈚 - :Japanese_free_of_charge_button:\n",
      "🔑 - :key:\n",
      "🎢 - :roller_coaster:\n",
      "🤪 - :zany_face:\n",
      "🐀 - :rat:\n",
      "💪🏻 - :flexed_biceps_light_skin_tone:\n",
      "🤩 - :star-struck:\n",
      "😘 - :face_blowing_a_kiss:\n",
      "😂 - :face_with_tears_of_joy:\n",
      "😡 - :enraged_face:\n",
      "✋ - :raised_hand:\n",
      "⚡ - :high_voltage:\n",
      "🌕 - :full_moon:\n",
      "🟢 - :green_circle:\n",
      "🐸 - :frog:\n",
      "❤ - :red_heart:\n",
      "✨ - :sparkles:\n",
      "🥸 - :disguised_face:\n",
      "🤷🏼‍♀ - :woman_shrugging_medium-light_skin_tone:\n",
      "✊ - :raised_fist:\n",
      "🎅🏻 - :Santa_Claus_light_skin_tone:\n",
      "⬇ - :down_arrow:\n",
      "🥒 - :cucumber:\n",
      "😝 - :squinting_face_with_tongue:\n",
      "☺ - :smiling_face:\n",
      "🌖 - :waning_gibbous_moon:\n",
      "🤯 - :exploding_head:\n",
      "😈 - :smiling_face_with_horns:\n",
      "🔹 - :small_blue_diamond:\n",
      "😀 - :grinning_face:\n",
      "😍 - :smiling_face_with_heart-eyes:\n",
      "💫 - :dizzy:\n",
      "💵 - :dollar_banknote:\n",
      "🤭 - :face_with_hand_over_mouth:\n",
      "☝ - :index_pointing_up:\n",
      "📨 - :incoming_envelope:\n",
      "👈🏻 - :backhand_index_pointing_left_light_skin_tone:\n",
      "😭 - :loudly_crying_face:\n",
      "💎 - :gem_stone:\n",
      "🔰 - :Japanese_symbol_for_beginner:\n",
      "🙃 - :upside-down_face:\n",
      "🤞🏻 - :crossed_fingers_light_skin_tone:\n",
      "👅 - :tongue:\n",
      "🇷🇺 - :Russia:\n",
      "⚽ - :soccer_ball:\n",
      "😋 - :face_savoring_food:\n",
      "👌 - :OK_hand:\n",
      "🌎 - :globe_showing_Americas:\n",
      "🤡 - :clown_face:\n",
      "😹 - :cat_with_tears_of_joy:\n",
      "💥 - :collision:\n",
      "🇨🇳 - :China:\n",
      "🤦🏽 - :person_facepalming_medium_skin_tone:\n",
      "🐷 - :pig_face:\n",
      "🙏🏽 - :folded_hands_medium_skin_tone:\n",
      "🌌 - :milky_way:\n",
      "😛 - :face_with_tongue:\n",
      "😾 - :pouting_cat:\n",
      "🤟 - :love-you_gesture:\n",
      "👻 - :ghost:\n",
      "🪂 - :parachute:\n",
      "😞 - :disappointed_face:\n",
      "🕺 - :man_dancing:\n",
      "🎼 - :musical_score:\n",
      "🙆‍♂ - :man_gesturing_OK:\n",
      "🤗 - :smiling_face_with_open_hands:\n",
      "🙋‍♂ - :man_raising_hand:\n",
      "✔ - :check_mark:\n",
      "🌙 - :crescent_moon:\n",
      "🍻 - :clinking_beer_mugs:\n",
      "🇧🇾 - :Belarus:\n",
      "🤙🏻 - :call_me_hand_light_skin_tone:\n",
      "🫡 - :saluting_face:\n",
      "🚫 - :prohibited:\n",
      "👈 - :backhand_index_pointing_left:\n",
      "💨 - :dashing_away:\n",
      "🙌🏼 - :raising_hands_medium-light_skin_tone:\n",
      "🤞🏼 - :crossed_fingers_medium-light_skin_tone:\n",
      "🤘 - :sign_of_the_horns:\n",
      "🌐 - :globe_with_meridians:\n",
      "😐 - :neutral_face:\n",
      "🤦🏼‍♂ - :man_facepalming_medium-light_skin_tone:\n",
      "▶ - :play_button:\n",
      "💬 - :speech_balloon:\n",
      "🥶 - :cold_face:\n",
      "✊🏼 - :raised_fist_medium-light_skin_tone:\n",
      "😰 - :anxious_face_with_sweat:\n",
      "🫣 - :face_with_peeking_eye:\n",
      "💪🏽 - :flexed_biceps_medium_skin_tone:\n",
      "🥴 - :woozy_face:\n",
      "🤠 - :cowboy_hat_face:\n",
      "ℹ️ - :information:\n",
      "😬 - :grimacing_face:\n",
      "🙋🏻‍♂ - :man_raising_hand_light_skin_tone:\n",
      "👍🏻 - :thumbs_up_light_skin_tone:\n",
      "❓ - :red_question_mark:\n",
      "👍🏼 - :thumbs_up_medium-light_skin_tone:\n",
      "👋🏻 - :waving_hand_light_skin_tone:\n",
      "💔 - :broken_heart:\n",
      "👏🏾 - :clapping_hands_medium-dark_skin_tone:\n",
      "🚨 - :police_car_light:\n",
      "⚓ - :anchor:\n",
      "😚 - :kissing_face_with_closed_eyes:\n",
      "🤟🏻 - :love-you_gesture_light_skin_tone:\n",
      "💚 - :green_heart:\n",
      "🥵 - :hot_face:\n",
      "🤤 - :drooling_face:\n",
      "😃 - :grinning_face_with_big_eyes:\n",
      "👆🏼 - :backhand_index_pointing_up_medium-light_skin_tone:\n",
      "💸 - :money_with_wings:\n",
      "👉🏻 - :backhand_index_pointing_right_light_skin_tone:\n",
      "🤞 - :crossed_fingers:\n",
      "🐗 - :boar:\n",
      "👀 - :eyes:\n",
      "🇵🇪 - :Peru:\n",
      "🐶 - :dog_face:\n",
      "😎 - :smiling_face_with_sunglasses:\n",
      "😢 - :crying_face:\n",
      "😜 - :winking_face_with_tongue:\n",
      "😄 - :grinning_face_with_smiling_eyes:\n",
      "👌🏻 - :OK_hand_light_skin_tone:\n",
      "💦 - :sweat_droplets:\n",
      "🥱 - :yawning_face:\n",
      "🙌🏻 - :raising_hands_light_skin_tone:\n",
      "🌝 - :full_moon_face:\n",
      "😌 - :relieved_face:\n",
      "😇 - :smiling_face_with_halo:\n",
      "💯 - :hundred_points:\n",
      "🤙🏽 - :call_me_hand_medium_skin_tone:\n",
      "🤷‍♂ - :man_shrugging:\n",
      "🔮 - :crystal_ball:\n",
      "🐁 - :mouse:\n",
      "🌘 - :waning_crescent_moon:\n",
      "🙊 - :speak-no-evil_monkey:\n",
      "👎 - :thumbs_down:\n",
      "✈ - :airplane:\n",
      "🥲 - :smiling_face_with_tear:\n",
      "🗣 - :speaking_head:\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"data/task1/train/subjects\"\n",
    "subjects = defaultdict(list)\n",
    "\n",
    "def extract_emojis(text):\n",
    "    return set(emoji_data['emoji'] for emoji_data in emoji.emoji_list(text))\n",
    "\n",
    "all_emojis = set()\n",
    "for filename in os.listdir(data_dir):\n",
    "    if filename.endswith(\".json\"):\n",
    "        with open(os.path.join(data_dir, filename), \"r\") as f:\n",
    "            messages = json.load(f)\n",
    "            nick = filename.split(\".\")[0]\n",
    "            for msg in messages:\n",
    "                message_text = str(msg[\"message\"]) if msg[\"message\"] is not None else \"\"\n",
    "                all_emojis.update(extract_emojis(message_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8115,
     "status": "ok",
     "timestamp": 1744013407276,
     "user": {
      "displayName": "Phúc Nguyễn Xuân",
      "userId": "14670273794783355842"
     },
     "user_tz": -420
    },
    "id": "tAGUiFCsZqls"
   },
   "outputs": [],
   "source": [
    "def map_emoji_to_spanish(emoji=None):\n",
    "    emoji_map = {\n",
    "        \"🔝\": \"arriba\",\n",
    "        \"👎\": \"no me gusta\",\n",
    "        \"😳\": \"sorprendido\",\n",
    "        \"4️⃣\": \"cuatro\",\n",
    "        \"🖐🏼\": \"mano abierta\",\n",
    "        \"💎\": \"diamante\",\n",
    "        \"🤣\": \"riendo fuerte\",\n",
    "        \"🤞🏻\": \"dedos cruzados\",\n",
    "        \"🍺\": \"cerveza\",\n",
    "        \"❣\": \"corazón exclamación\",\n",
    "        \"🤡\": \"payaso\",\n",
    "        \"🎅🏻\": \"Papá Noel\",\n",
    "        \"⬆\": \"subir\",\n",
    "        \"💸\": \"dinero volando\",\n",
    "        \"🤤\": \"babeando\",\n",
    "        \"❌\": \"cruz\",\n",
    "        \"🙌🏻\": \"manos arriba\",\n",
    "        \"🤩\": \"asombrado\",\n",
    "        \"🇵🇪\": \"Perú\",\n",
    "        \"🤠\": \"vaquero\",\n",
    "        \"🟣\": \"círculo morado\",\n",
    "        \"🖐🏽\": \"mano abierta\",\n",
    "        \"🙃\": \"cara invertida\",\n",
    "        \"🐸\": \"rana\",\n",
    "        \"👆🏼\": \"señalando arriba\",\n",
    "        \"🈚\": \"gratis\",\n",
    "        \"🌐\": \"mundo\",\n",
    "        \"🎁\": \"regalo\",\n",
    "        \"🎉\": \"celebración\",\n",
    "        \"😵‍💫\": \"mareado\",\n",
    "        \"🌝\": \"luna llena\",\n",
    "        \"🙋‍♂\": \"hombre levantando mano\",\n",
    "        \"3️⃣\": \"tres\",\n",
    "        \"🔮\": \"bola de cristal\",\n",
    "        \"😰\": \"nervioso\",\n",
    "        \"😨\": \"miedo\",\n",
    "        \"❓\": \"pregunta\",\n",
    "        \"☝🏻\": \"dedo arriba\",\n",
    "        \"🥲\": \"lágrimas de alegría\",\n",
    "        \"✊🏼\": \"puño levantado\",\n",
    "        \"✊\": \"puño\",\n",
    "        \"🧘🏻‍♂\": \"meditación\",\n",
    "        \"🧐\": \"curioso\",\n",
    "        \"👏🏾\": \"aplausos\",\n",
    "        \"🐳\": \"ballena\",\n",
    "        \"💪🏼\": \"fuerza\",\n",
    "        \"✅\": \"aprobado\",\n",
    "        \"🤦🏼‍♂\": \"vergüenza\",\n",
    "        \"😍\": \"enamorado\",\n",
    "        \"👻\": \"fantasma\",\n",
    "        \"😂\": \"riendo\",\n",
    "        \"💪🏻\": \"fuerte\",\n",
    "        \"🫤\": \"decepción\",\n",
    "        \"⚽\": \"fútbol\",\n",
    "        \"🥚\": \"huevo\",\n",
    "        \"🙏\": \"rezando\",\n",
    "        \"🤙\": \"llámame\",\n",
    "        \"🙄\": \"aburrido\",\n",
    "        \"😲\": \"asombro\",\n",
    "        \"♥\": \"corazón\",\n",
    "        \"🍎\": \"manzana\",\n",
    "        \"🐻\": \"oso\",\n",
    "        \"🤪\": \"loco\",\n",
    "        \"👆🏽\": \"señalando arriba\",\n",
    "        \"🎢\": \"montaña rusa\",\n",
    "        \"🙌\": \"celebrando\",\n",
    "        \"🌘\": \"luna menguante\",\n",
    "        \"🫡\": \"saludo\",\n",
    "        \"🙋🏻‍♀\": \"mujer levantando mano\",\n",
    "        \"🤦‍♂\": \"error\",\n",
    "        \"🌊\": \"ola\",\n",
    "        \"😉\": \"guiño\",\n",
    "        \"🥶\": \"frío\",\n",
    "        \"💋\": \"beso\",\n",
    "        \"🇺🇦\": \"Ucrania\",\n",
    "        \"😶‍🌫\": \"confundido\",\n",
    "        \"🌬\": \"viento\",\n",
    "        \"💩\": \"mierda\",\n",
    "        \"👌🏼\": \"perfecto\",\n",
    "        \"🙆‍♂\": \"hombre OK\",\n",
    "        \"💪🏽\": \"fuerza\",\n",
    "        \"😱\": \"gritando\",\n",
    "        \"1️⃣\": \"uno\",\n",
    "        \"🤘\": \"rock\",\n",
    "        \"👉\": \"señalando derecha\",\n",
    "        \"🙂\": \"sonriendo\",\n",
    "        \"👁\": \"ojo\",\n",
    "        \"👀\": \"ojos\",\n",
    "        \"🔥\": \"fuego\",\n",
    "        \"⏺\": \"grabar\",\n",
    "        \"😅\": \"sudando\",\n",
    "        \"❗\": \"exclamación\",\n",
    "        \"😕\": \"confuso\",\n",
    "        \"🥒\": \"pepino\",\n",
    "        \"🎂\": \"torta\",\n",
    "        \"😥\": \"aliviado\",\n",
    "        \"✌🏽\": \"victoria\",\n",
    "        \"🎾\": \"tenis\",\n",
    "        \"💚\": \"corazón verde\",\n",
    "        \"💔\": \"corazón roto\",\n",
    "        \"👍\": \"bien\",\n",
    "        \"🐶\": \"perro\",\n",
    "        \"✔\": \"verificado\",\n",
    "        \"✌🏻\": \"paz\",\n",
    "        \"💪\": \"músculo\",\n",
    "        \"🎈\": \"globo\",\n",
    "        \"🤑\": \"dinero en la cara\",\n",
    "        \"😾\": \"gato enfadado\",\n",
    "        \"💵\": \"billete\",\n",
    "        \"👋🏻\": \"saludando\",\n",
    "        \"👈🏻\": \"señalando izquierda\",\n",
    "        \"💰\": \"bolsa de dinero\",\n",
    "        \"🎼\": \"música\",\n",
    "        \"🐮\": \"vaca\",\n",
    "        \"🇦🇷\": \"Argentina\",\n",
    "        \"🤷🏼‍♀\": \"mujer encogiéndose\",\n",
    "        \"💃\": \"bailando\",\n",
    "        \"🤮\": \"vomitando\",\n",
    "        \"🇷🇺\": \"Rusia\",\n",
    "        \"😎\": \"genial\",\n",
    "        \"🥳\": \"fiesta\",\n",
    "        \"⚰\": \"ataúd\",\n",
    "        \"💯\": \"cien puntos\",\n",
    "        \"📈\": \"gráfico subiendo\",\n",
    "        \"😭\": \"llorando\",\n",
    "        \"😪\": \"somnoliento\",\n",
    "        \"🤞🏼\": \"suerte\",\n",
    "        \"🤦🏽‍♂\": \"hombre avergonzado\",\n",
    "        \"▶\": \"reproducir\",\n",
    "        \"⛔\": \"prohibido\",\n",
    "        \"🎶\": \"notas musicales\",\n",
    "        \"🙊\": \"mono callado\",\n",
    "        \"🌚\": \"luna nueva\",\n",
    "        \"👏\": \"aplaudiendo\",\n",
    "        \"🙏🏽\": \"rezando\",\n",
    "        \"😄\": \"feliz\",\n",
    "        \"🤦🏻‍♂\": \"error hombre\",\n",
    "        \"🇨🇳\": \"China\",\n",
    "        \"👌🏻\": \"OK\",\n",
    "        \"🤙🏻\": \"llámame\",\n",
    "        \"🇳🇬\": \"Nigeria\",\n",
    "        \"😃\": \"alegre\",\n",
    "        \"ℹ️\": \"información\",\n",
    "        \"🗣\": \"hablando\",\n",
    "        \"🙌🏼\": \"manos levantadas\",\n",
    "        \"🤞\": \"cruzando dedos\",\n",
    "        \"😜\": \"broma\",\n",
    "        \"🎵\": \"nota musical\",\n",
    "        \"🤟\": \"te amo\",\n",
    "        \"✈\": \"avión\",\n",
    "        \"👌🏽\": \"perfecto\",\n",
    "        \"🤦🏽\": \"vergüenza\",\n",
    "        \"👍🏾\": \"bien\",\n",
    "        \"🔹\": \"diamante azul\",\n",
    "        \"😝\": \"lengua fuera\",\n",
    "        \"💶\": \"euro\",\n",
    "        \"🤓\": \"nerd\",\n",
    "        \"😶\": \"sin expresión\",\n",
    "        \"🐁\": \"ratón\",\n",
    "        \"🐗\": \"jabalí\",\n",
    "        \"🤦🏻‍♀\": \"mujer avergonzada\",\n",
    "        \"🍏\": \"manzana verde\",\n",
    "        \"🟢\": \"círculo verde\",\n",
    "        \"🙌🏽\": \"celebración\",\n",
    "        \"🇪🇸\": \"España\",\n",
    "        \"✨\": \"brillo\",\n",
    "        \"🤷🏻‍♂\": \"hombre encogiéndose\",\n",
    "        \"🚨\": \"alarma\",\n",
    "        \"🥰\": \"amor\",\n",
    "        \"☺\": \"sonrisa\",\n",
    "        \"🤷‍♂\": \"duda\",\n",
    "        \"🤯\": \"cabeza explotando\",\n",
    "        \"🥺\": \"suplicando\",\n",
    "        \"🐟\": \"pez\",\n",
    "        \"🇮🇳\": \"India\",\n",
    "        \"😐\": \"neutral\",\n",
    "        \"😁\": \"sonriendo amplio\",\n",
    "        \"🙋🏻‍♂\": \"levantando mano\",\n",
    "        \"😓\": \"sudor\",\n",
    "        \"🕺\": \"bailando\",\n",
    "        \"😯\": \"sorprendido\",\n",
    "        \"👉🏻\": \"señalando derecha\",\n",
    "        \"💥\": \"explosión\",\n",
    "        \"😢\": \"llorando\",\n",
    "        \"🦖\": \"T-Rex\",\n",
    "        \"⚡\": \"rayo\",\n",
    "        \"😴\": \"durmiendo\",\n",
    "        \"🫣\": \"espiando\",\n",
    "        \"😻\": \"gato enamorado\",\n",
    "        \"🥵\": \"caliente\",\n",
    "        \"👍🏻\": \"pulgar arriba\",\n",
    "        \"🇧🇾\": \"Bielorrusia\",\n",
    "        \"🤷🏽‍♀\": \"mujer dudando\",\n",
    "        \"😋\": \"saboreando\",\n",
    "        \"🚫\": \"prohibido\",\n",
    "        \"👅\": \"lengua\",\n",
    "        \"😆\": \"riendo mucho\",\n",
    "        \"😊\": \"sonriendo feliz\",\n",
    "        \"😇\": \"ángel\",\n",
    "        \"😠\": \"enojado\",\n",
    "        \"🌎\": \"Américas\",\n",
    "        \"⬇\": \"bajar\",\n",
    "        \"😞\": \"triste\",\n",
    "        \"🔵\": \"círculo azul\",\n",
    "        \"📨\": \"correo\",\n",
    "        \"👆\": \"arriba\",\n",
    "        \"😘\": \"besando\",\n",
    "        \"🌖\": \"luna gibosa\",\n",
    "        \"❤\": \"corazón rojo\",\n",
    "        \"☝\": \"dedo arriba\",\n",
    "        \"✌\": \"victoria\",\n",
    "        \"🍻\": \"brindis\",\n",
    "        \"🤝\": \"apretón de manos\",\n",
    "        \"👋\": \"saludo\",\n",
    "        \"💲\": \"dólar\",\n",
    "        \"👍🏼\": \"bien\",\n",
    "        \"🚶🏻‍♂\": \"hombre caminando\",\n",
    "        \"🤔\": \"pensando\",\n",
    "        \"😹\": \"gato riendo\",\n",
    "        \"🫵\": \"señalando\",\n",
    "        \"🤭\": \"riendo callado\",\n",
    "        \"🪂\": \"paracaídas\",\n",
    "        \"😈\": \"diablo\",\n",
    "        \"🔰\": \"principiante\",\n",
    "        \"🫀\": \"corazón\",\n",
    "        \"😒\": \"molesto\",\n",
    "        \"🤷\": \"no sé\",\n",
    "        \"😀\": \"felicidad\",\n",
    "        \"🍀\": \"trébol\",\n",
    "        \"🔪\": \"cuchillo\",\n",
    "        \"😮\": \"boca abierta\",\n",
    "        \"💬\": \"hablar\",\n",
    "        \"✋\": \"mano levantada\",\n",
    "        \"😌\": \"alivio\",\n",
    "        \"💦\": \"sudor\",\n",
    "        \"🤷🏼‍♂\": \"duda\",\n",
    "        \"☹\": \"tristeza\",\n",
    "        \"🤨\": \"sospecha\",\n",
    "        \"🤙🏽\": \"llámame\",\n",
    "        \"🔻\": \"triángulo abajo\",\n",
    "        \"🛍\": \"compras\",\n",
    "        \"🤧\": \"estornudo\",\n",
    "        \"💫\": \"mareo\",\n",
    "        \"👼\": \"ángel\",\n",
    "        \"🤌\": \"pellizco\",\n",
    "        \"💨\": \"rápido\",\n",
    "        \"😛\": \"lengua fuera\",\n",
    "        \"🎄\": \"árbol de Navidad\",\n",
    "        \"🥹\": \"lágrimas contenidas\",\n",
    "        \"☀\": \"sol\",\n",
    "        \"🌕\": \"luna llena\",\n",
    "        \"🇺🇸\": \"Estados Unidos\",\n",
    "        \"👏🏼\": \"aplausos\",\n",
    "        \"‼\": \"doble exclamación\",\n",
    "        \"🚀\": \"cohete\",\n",
    "        \"😡\": \"furioso\",\n",
    "        \"😬\": \"nervios\",\n",
    "        \"🔴\": \"círculo rojo\",\n",
    "        \"🙏🏻\": \"orando\",\n",
    "        \"🙈\": \"mono tapándose\",\n",
    "        \"🦥\": \"perezoso\",\n",
    "        \"🌙\": \"luna creciente\",\n",
    "        \"👈\": \"señalando izquierda\",\n",
    "        \"🐷\": \"cerdo\",\n",
    "        \"🥸\": \"disfrazado\",\n",
    "        \"😏\": \"sonrisa pícara\",\n",
    "        \"😚\": \"beso cerrado\",\n",
    "        \"⚓\": \"ancla\",\n",
    "        \"👌\": \"OK\",\n",
    "        \"🤟🏻\": \"te amo\",\n",
    "        \"🌌\": \"vía láctea\",\n",
    "        \"⚠\": \"advertencia\",\n",
    "        \"🥱\": \"bostezando\",\n",
    "        \"🐬\": \"delfín\",\n",
    "        \"📊\": \"gráfico\",\n",
    "        \"🐀\": \"rata\",\n",
    "        \"🤗\": \"abrazo\",\n",
    "        \"😔\": \"pensativo\",\n",
    "        \"👏🏻\": \"aplaudiendo\",\n",
    "        \"🇧🇬\": \"Bulgaria\",\n",
    "        \"🥴\": \"mareado\"\n",
    "    }\n",
    "    if emoji is None:\n",
    "        return emoji_map  # Trả về toàn bộ từ điển nếu không truyền emoji\n",
    "    return emoji_map.get(emoji, emoji)  # Trả về ánh xạ hoặc emoji gốc\n",
    "\n",
    "def replace_emojis_in_text(text):\n",
    "    result = text\n",
    "    for emoji, spanish_text in map_emoji_to_spanish().items():\n",
    "        result = result.replace(emoji, f\" {spanish_text} \")\n",
    "    words = result.split()\n",
    "    if not words:\n",
    "        return \"\"\n",
    "    cleaned_words = [words[0]]\n",
    "    for i in range(1, len(words)):\n",
    "        if words[i] != words[i-1]:\n",
    "            cleaned_words.append(words[i])\n",
    "    return \" \".join(cleaned_words).strip()\n",
    "\n",
    "for filename in os.listdir(data_dir):\n",
    "    if filename.endswith(\".json\"):\n",
    "        with open(os.path.join(data_dir, filename), \"r\") as f:\n",
    "            messages = json.load(f)\n",
    "            nick = filename.split(\".\")[0]\n",
    "            subjects[nick] = [\n",
    "                replace_emojis_in_text(str(msg[\"message\"]) if msg[\"message\"] is not None else \"\")\n",
    "                for msg in messages\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1744015989860,
     "user": {
      "displayName": "Phúc Nguyễn Xuân",
      "userId": "14670273794783355842"
     },
     "user_tz": -420
    },
    "id": "YIux-eMKafnG",
    "outputId": "ba8d66c8-f1f1-43b8-b9be-a245e18992f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Voy cargando la escopeta pa longuear alguna monedilla',\n",
       " 'Todavía no',\n",
       " 'Esto está más aburrido',\n",
       " 'Falta mucho para que entren los chinos ?',\n",
       " 'Por señales de Facu ?',\n",
       " 'Compartí ahora bien',\n",
       " 'Y compartilos ahora . Igual te van a banear cuando lean esto riendo',\n",
       " 'Sacate la papa de la boca',\n",
       " 'Se picó la clande',\n",
       " 'riendo',\n",
       " 'Screenshot ( 6 mar . 2022 20:03 : 38 )',\n",
       " 'La paciencia sudando',\n",
       " 'Divino ! aplaudiendo',\n",
       " 'Screenshot ( 6 mar . 2022 20:22 : 39 )',\n",
       " 'Cerrada lunitaa enamorado',\n",
       " 'mono tapándose',\n",
       " 'Un short en 38k es lo mismo que ir al casino riendo',\n",
       " 'Recuperar que ?',\n",
       " 'Si no entra una ballena generosa en los próximos minutos btc se pega un palo',\n",
       " 'Vamoooo mañana se come enamorado',\n",
       " 'De proyectos no se absolutamente nada sonriendo feliz solo tradeo cualquier cosa que se mueva riendo',\n",
       " 'riendo aplaudiendo',\n",
       " '4 k en un trade ? Mierda ! Que haces acá hermano',\n",
       " 'Anoche no estaban meta long todos ?',\n",
       " 'Yo vi que subian longs a dos manos .. pero no recuerdo si era a anoche o el viernes',\n",
       " 'El miedo mueve más que el fomo',\n",
       " 'Seguro . Esta semana más tardar',\n",
       " 'Screenshot ( 7 mar . 2022 0:35 : 57 ) . Vamooooo que se comeeeee',\n",
       " 'Siguiendo a btc',\n",
       " 'Estaba long , cerré y ahora veremos si hice bien o me largo a llorar',\n",
       " 'Vamos lunita mí amor',\n",
       " 'Yes',\n",
       " 'Dale Facu . Compra btc así pumpea riendo',\n",
       " 'Espero que suba mucho . Quiero platita',\n",
       " 'Hoy se come genial',\n",
       " 'Se comeeeeee genial',\n",
       " 'Seee . No toco más nada hasta mañana',\n",
       " 'Apagó la compu para no cagarla riendo',\n",
       " 'riendo de una',\n",
       " 'Y ahora pabajoo sudando',\n",
       " 'Siempre sin ... Estoy cansado de ella mechazos',\n",
       " 'riendo',\n",
       " 'Cerrada genial',\n",
       " 'Hace años que trabajo así . Prefiero el stop manual',\n",
       " 'En historial',\n",
       " 'Claro ... Son formas . No pongo stop peor estoy con el ojo en la pantalla cuando opero .',\n",
       " 'Ahhh si el porcentaje creo que no se puede . Solo con a operación abierta',\n",
       " 'Ojalá Bro',\n",
       " 'Acusalo con tu mamá kikooo',\n",
       " 'Screenshot (8 mar . 2022 14:16 : 28 ) te amo biden enamorado',\n",
       " 'Gracia amigo',\n",
       " 'Yes . argento',\n",
       " 'Habló biden',\n",
       " 'Cerrado genial se come',\n",
       " 'El cierre o las entradas ?',\n",
       " 'Estabab todas en suporte y biden terminó el discurso diciendo que no hará nada con la guerra . Regaladas',\n",
       " 'Gracias Bro',\n",
       " 'Parece que no piensa retroceder hombre encogiéndose habrá que esperar',\n",
       " 'Todo el día haciendo Plata y en esta subía no metí ni un long riendo fuerte riendo fuerte riendo fuerte',\n",
       " 'Btc mete liquidaciones a la baja y luego cohete',\n",
       " 'Primero debería buscar los 42600 . Si rompe , a los 44000',\n",
       " 'Cuál triángulo ?',\n",
       " 'Lunita se paga el asado enamorado',\n",
       " 'Si , Justo ahí Por qué está a próxima a la línea de tendencia que había roto . Y no me animé a long',\n",
       " 'Se comeeeeeeee genial',\n",
       " 'Hoy se comió gracias a powel',\n",
       " 'user 9092 - London capital group',\n",
       " 'Se come genial',\n",
       " 'Mañana se come asado',\n",
       " 'Comparto mí felicidad como el grupo . Cómo hacen todos sorprendido',\n",
       " 'Ya dijo',\n",
       " 'Justo estaba por cerrar las operaciones furioso',\n",
       " 'Yo no',\n",
       " 'Rezar',\n",
       " 'Depende directamente de la tendencia ... En tendencia bajista te user 15930 más resultados los shorts y viceversa',\n",
       " 'Buenas gente . Alguien de acá utiliza paxuful ?',\n",
       " 'Paxful era . Jaja',\n",
       " 'Buenas gente . Una pregunta bien de ignorante . Alguien de acá utilizó el bono de bienvenida de huobi ? Es real eso ? Es tan fácil como dicen ?',\n",
       " 'Ah ... Que truchada',\n",
       " 'Sobrevivir',\n",
       " 'Claro . Depende donde y que tipo de vida . Yo con 300 al mes muero de angustia',\n",
       " 'Ni a palos . Cunado compraste pan por última vez ?',\n",
       " 'Acá en mí barrio 300 para arriba',\n",
       " 'No sé dónde viven ustedes o que comen . Pero yo acá en zona norte de BS AS . Con 300 dolares por mes solo me alcanza para comer . Y ahí ajustado',\n",
       " 'Tus hijos no serán compañeros de los míos no ? riendo Ami con 300 tampoco llego a pagar el cole',\n",
       " '20 por días no está mal . Pero solo para comer y hasta ahi']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjects['user10343']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 319,
     "status": "ok",
     "timestamp": 1744013467217,
     "user": {
      "displayName": "Phúc Nguyễn Xuân",
      "userId": "14670273794783355842"
     },
     "user_tz": -420
    },
    "id": "PKbYkJtcgk9_",
    "outputId": "ae8b4ec7-7065-4fea-ce35-fa7cb356b488"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tổng số mẫu: 528, Phân bố nhãn: [356 172]\n"
     ]
    }
   ],
   "source": [
    "task1_labels = {}\n",
    "with open(\"data/task1/train/gold_task1.txt\", \"r\") as f:\n",
    "    next(f)\n",
    "    for line in f:\n",
    "        nick, risk = line.strip().split(\",\")\n",
    "        task1_labels[nick] = int(risk)\n",
    "\n",
    "messages = []\n",
    "labels = []\n",
    "for nick, subject_messages in subjects.items():\n",
    "    if nick in task1_labels:\n",
    "        if task1_labels[nick] == 0:\n",
    "            msg_len = len(subject_messages)\n",
    "            if msg_len > 1:\n",
    "                split_point = msg_len // 2\n",
    "                messages.append(subject_messages[:split_point])\n",
    "                messages.append(subject_messages[split_point:])\n",
    "                labels.extend([0, 0])\n",
    "            else:\n",
    "                messages.append(subject_messages)\n",
    "                labels.append(0)\n",
    "        else:\n",
    "            messages.append(subject_messages)\n",
    "            labels.append(task1_labels[nick])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1744013414938,
     "user": {
      "displayName": "Phúc Nguyễn Xuân",
      "userId": "14670273794783355842"
     },
     "user_tz": -420
    },
    "id": "ZhnnZf4yPh4d"
   },
   "outputs": [],
   "source": [
    "class EmbDataset(Dataset):\n",
    "    def __init__(self, embeddings, labels):\n",
    "        self.embeddings = embeddings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.embeddings[idx], self.labels[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1744013415750,
     "user": {
      "displayName": "Phúc Nguyễn Xuân",
      "userId": "14670273794783355842"
     },
     "user_tz": -420
    },
    "id": "Pyr0l8M8Pw2h"
   },
   "outputs": [],
   "source": [
    "class EmbDatasetRNNAug(Dataset):\n",
    "    def __init__(self, embeddings, labels, thr_rng=0.7, n_msg=10):\n",
    "        self.embeddings = embeddings\n",
    "        self.labels = labels\n",
    "        self.emb0 = [embeddings[i] for i in range(len(labels)) if labels[i] == 0]\n",
    "        self.thr_rng = thr_rng\n",
    "        self.n_msg = n_msg\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.labels[idx] == 0:\n",
    "            nr_msg = np.random.randint(1, len(self.embeddings[idx]) + 1)\n",
    "            return self.embeddings[idx][:nr_msg], self.labels[idx]\n",
    "        else:\n",
    "            rnd = np.random.uniform()\n",
    "            if rnd > self.thr_rng:\n",
    "                neutral = self.emb0[np.random.randint(0, len(self.emb0))]\n",
    "                n_extra = np.random.randint(1, min(len(neutral), self.n_msg))\n",
    "                return np.concatenate([neutral[:n_extra], self.embeddings[idx]], axis=0), self.labels[idx]\n",
    "            return self.embeddings[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1744013417276,
     "user": {
      "displayName": "Phúc Nguyễn Xuân",
      "userId": "14670273794783355842"
     },
     "user_tz": -420
    },
    "id": "2pt2oMhJxVbI"
   },
   "outputs": [],
   "source": [
    "def make_plot(train_scores, val_scores, y_label, figsize=(8,5)):\n",
    "    fig, ax = plt.subplots(1,1,figsize=figsize)\n",
    "    ax.plot(train_scores, label='Train')\n",
    "    ax.plot(val_scores, label='Val')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel(y_label)\n",
    "    ax.legend()\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1744013418401,
     "user": {
      "displayName": "Phúc Nguyễn Xuân",
      "userId": "14670273794783355842"
     },
     "user_tz": -420
    },
    "id": "t_uyzb9n5bnZ"
   },
   "outputs": [],
   "source": [
    "def get_cls_embeddings(all_messages, model, tokenizer, device, m_length=96):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for subject_messages in tqdm(all_messages):\n",
    "            input = tokenizer(subject_messages, padding=True, truncation=True, max_length=m_length, return_tensors='pt')\n",
    "            output = model(**input.to(device))\n",
    "            embeddings.append(output.last_hidden_state[:, 0, :].cpu().numpy())\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1744015975200,
     "user": {
      "displayName": "Phúc Nguyễn Xuân",
      "userId": "14670273794783355842"
     },
     "user_tz": -420
    },
    "id": "dt62Oejy7HvO"
   },
   "outputs": [],
   "source": [
    "def lstm_collate(batch):\n",
    "    labels = [x[1] for x in batch]\n",
    "    labels = torch.tensor(labels, dtype=torch.long)\n",
    "    data = [torch.tensor(x[0], dtype=torch.float32) for x in batch]\n",
    "    batch_data = pad_sequence(data)\n",
    "    lens = torch.tensor([len(x) for x in data], dtype=torch.long).unsqueeze(0).unsqueeze(-1)\n",
    "    lens -= 1\n",
    "    return batch_data, lens, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1744015995746,
     "user": {
      "displayName": "Phúc Nguyễn Xuân",
      "userId": "14670273794783355842"
     },
     "user_tz": -420
    },
    "id": "JXy8u0t8Ugo7"
   },
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_size, h_size, output_dim, dropout=0):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size, h_size, num_layers=1, batch_first=False, dropout=dropout, bidirectional=True)\n",
    "        self.attention = nn.Linear(2 * h_size, 1)\n",
    "        self.classifier = nn.Linear(2 * h_size, output_dim)\n",
    "\n",
    "    def forward(self, seq_data, seq_lens, state=None):\n",
    "        lstm_out, _ = self.lstm(seq_data)\n",
    "        attention_weights = torch.softmax(self.attention(lstm_out), dim=0)\n",
    "        context_vector = torch.sum(attention_weights * lstm_out, dim=0)\n",
    "        return self.classifier(context_vector)\n",
    "\n",
    "    def predict_all_timesteps(self, seq_data, seq_lens, state=None):\n",
    "        lstm_out, _ = self.lstm(seq_data)\n",
    "        attention_weights = torch.softmax(self.attention(lstm_out), dim=0)\n",
    "        logits_all = self.classifier(lstm_out)\n",
    "        pred_all = torch.argmax(logits_all, dim=2)\n",
    "        ts_predictions = [pred_all[:seq_lens[0, i].item(), i].squeeze().cpu().numpy() for i in range(pred_all.shape[1])]\n",
    "        return ts_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 52694,
     "status": "ok",
     "timestamp": 1744013522812,
     "user": {
      "displayName": "Phúc Nguyễn Xuân",
      "userId": "14670273794783355842"
     },
     "user_tz": -420
    },
    "id": "iXD3RXb6c_TR",
    "outputId": "a0e1d29e-6894-4fcf-b480-c8bfcd56d713"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at pysentimiento/robertuito-sentiment-analysis and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 528/528 [00:31<00:00, 16.93it/s]\n"
     ]
    }
   ],
   "source": [
    "# Thiết lập và huấn luyện\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "name = 'pysentimiento/robertuito-sentiment-analysis'\n",
    "tokenizer = AutoTokenizer.from_pretrained(name)\n",
    "model = AutoModel.from_pretrained(name)\n",
    "embs = get_cls_embeddings(messages, model, tokenizer, device, m_length=96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 886
    },
    "executionInfo": {
     "elapsed": 169504,
     "status": "error",
     "timestamp": 1744019650631,
     "user": {
      "displayName": "Phúc Nguyễn Xuân",
      "userId": "14670273794783355842"
     },
     "user_tz": -420
    },
    "id": "ZVWsx0ZnhKfh",
    "outputId": "7ff975f2-9060-4a73-acb4-2764da59ad4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phân bố nhãn trong tập train:\n",
      "[282 278]\n",
      "Phân bố nhãn trong tập test:\n",
      "[74 66]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 150/150 [03:06<00:00,  1.24s/it, loss=0.1489, val_f1=0.9569]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Kết quả cho h_size: 96, batch_size: 2 ===\u001b[0m\n",
      "+---------------------+--------+\n",
      "| Metric              |  Value |\n",
      "+---------------------+--------+\n",
      "| Epoch tốt nhất      |    117 |\n",
      "| Val Macro F1        | 0.9713 |\n",
      "| Train_eval Macro F1 | 0.9982 |\n",
      "+---------------------+--------+\n",
      "\n",
      "\u001b[32mValidation Set:\u001b[0m\n",
      "           Pred 0   Pred 1\n",
      "  True 0       72        2\n",
      "  True 1        2       64\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        74\n",
      "           1       0.97      0.97      0.97        66\n",
      "\n",
      "    accuracy                           0.97       140\n",
      "   macro avg       0.97      0.97      0.97       140\n",
      "weighted avg       0.97      0.97      0.97       140\n",
      "\n",
      "\n",
      "\u001b[33mTrain_eval Set:\u001b[0m\n",
      "           Pred 0   Pred 1\n",
      "  True 0       72        2\n",
      "  True 1        4       62\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       282\n",
      "           1       1.00      1.00      1.00       278\n",
      "\n",
      "    accuracy                           1.00       560\n",
      "   macro avg       1.00      1.00      1.00       560\n",
      "weighted avg       1.00      1.00      1.00       560\n",
      "\n",
      "\u001b[36m==================================================\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 150/150 [01:53<00:00,  1.32it/s, loss=0.1862, val_f1=0.9353]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Kết quả cho h_size: 96, batch_size: 4 ===\u001b[0m\n",
      "+---------------------+--------+\n",
      "| Metric              |  Value |\n",
      "+---------------------+--------+\n",
      "| Epoch tốt nhất      |    142 |\n",
      "| Val Macro F1        | 0.9498 |\n",
      "| Train_eval Macro F1 | 1.0000 |\n",
      "+---------------------+--------+\n",
      "\n",
      "\u001b[32mValidation Set:\u001b[0m\n",
      "           Pred 0   Pred 1\n",
      "  True 0       71        3\n",
      "  True 1        4       62\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95        74\n",
      "           1       0.95      0.94      0.95        66\n",
      "\n",
      "    accuracy                           0.95       140\n",
      "   macro avg       0.95      0.95      0.95       140\n",
      "weighted avg       0.95      0.95      0.95       140\n",
      "\n",
      "\n",
      "\u001b[33mTrain_eval Set:\u001b[0m\n",
      "           Pred 0   Pred 1\n",
      "  True 0       71        3\n",
      "  True 1        6       60\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       282\n",
      "           1       1.00      1.00      1.00       278\n",
      "\n",
      "    accuracy                           1.00       560\n",
      "   macro avg       1.00      1.00      1.00       560\n",
      "weighted avg       1.00      1.00      1.00       560\n",
      "\n",
      "\u001b[36m==================================================\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 150/150 [01:05<00:00,  2.30it/s, loss=0.1989, val_f1=0.8049]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Kết quả cho h_size: 96, batch_size: 8 ===\u001b[0m\n",
      "+---------------------+--------+\n",
      "| Metric              |  Value |\n",
      "+---------------------+--------+\n",
      "| Epoch tốt nhất      |     49 |\n",
      "| Val Macro F1        | 0.9000 |\n",
      "| Train_eval Macro F1 | 0.9821 |\n",
      "+---------------------+--------+\n",
      "\n",
      "\u001b[32mValidation Set:\u001b[0m\n",
      "           Pred 0   Pred 1\n",
      "  True 0       62       12\n",
      "  True 1        2       64\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.84      0.90        74\n",
      "           1       0.84      0.97      0.90        66\n",
      "\n",
      "    accuracy                           0.90       140\n",
      "   macro avg       0.91      0.90      0.90       140\n",
      "weighted avg       0.91      0.90      0.90       140\n",
      "\n",
      "\n",
      "\u001b[33mTrain_eval Set:\u001b[0m\n",
      "           Pred 0   Pred 1\n",
      "  True 0       49       25\n",
      "  True 1        2       64\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98       282\n",
      "           1       0.97      1.00      0.98       278\n",
      "\n",
      "    accuracy                           0.98       560\n",
      "   macro avg       0.98      0.98      0.98       560\n",
      "weighted avg       0.98      0.98      0.98       560\n",
      "\n",
      "\u001b[36m==================================================\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 150/150 [03:45<00:00,  1.51s/it, loss=0.1474, val_f1=0.9071]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Kết quả cho h_size: 128, batch_size: 2 ===\u001b[0m\n",
      "+---------------------+--------+\n",
      "| Metric              |  Value |\n",
      "+---------------------+--------+\n",
      "| Epoch tốt nhất      |     68 |\n",
      "| Val Macro F1        | 0.9569 |\n",
      "| Train_eval Macro F1 | 1.0000 |\n",
      "+---------------------+--------+\n",
      "\n",
      "\u001b[32mValidation Set:\u001b[0m\n",
      "           Pred 0   Pred 1\n",
      "  True 0       72        2\n",
      "  True 1        4       62\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96        74\n",
      "           1       0.97      0.94      0.95        66\n",
      "\n",
      "    accuracy                           0.96       140\n",
      "   macro avg       0.96      0.96      0.96       140\n",
      "weighted avg       0.96      0.96      0.96       140\n",
      "\n",
      "\n",
      "\u001b[33mTrain_eval Set:\u001b[0m\n",
      "           Pred 0   Pred 1\n",
      "  True 0       65        9\n",
      "  True 1        4       62\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       282\n",
      "           1       1.00      1.00      1.00       278\n",
      "\n",
      "    accuracy                           1.00       560\n",
      "   macro avg       1.00      1.00      1.00       560\n",
      "weighted avg       1.00      1.00      1.00       560\n",
      "\n",
      "\u001b[36m==================================================\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 150/150 [02:29<00:00,  1.00it/s, loss=0.1878, val_f1=0.9284]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Kết quả cho h_size: 128, batch_size: 4 ===\u001b[0m\n",
      "+---------------------+--------+\n",
      "| Metric              |  Value |\n",
      "+---------------------+--------+\n",
      "| Epoch tốt nhất      |    130 |\n",
      "| Val Macro F1        | 0.9569 |\n",
      "| Train_eval Macro F1 | 1.0000 |\n",
      "+---------------------+--------+\n",
      "\n",
      "\u001b[32mValidation Set:\u001b[0m\n",
      "           Pred 0   Pred 1\n",
      "  True 0       72        2\n",
      "  True 1        4       62\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96        74\n",
      "           1       0.97      0.94      0.95        66\n",
      "\n",
      "    accuracy                           0.96       140\n",
      "   macro avg       0.96      0.96      0.96       140\n",
      "weighted avg       0.96      0.96      0.96       140\n",
      "\n",
      "\n",
      "\u001b[33mTrain_eval Set:\u001b[0m\n",
      "           Pred 0   Pred 1\n",
      "  True 0       68        6\n",
      "  True 1        4       62\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       282\n",
      "           1       1.00      1.00      1.00       278\n",
      "\n",
      "    accuracy                           1.00       560\n",
      "   macro avg       1.00      1.00      1.00       560\n",
      "weighted avg       1.00      1.00      1.00       560\n",
      "\n",
      "\u001b[36m==================================================\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 150/150 [01:51<00:00,  1.35it/s, loss=0.1958, val_f1=0.8712]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== Kết quả cho h_size: 128, batch_size: 8 ===\u001b[0m\n",
      "+---------------------+--------+\n",
      "| Metric              |  Value |\n",
      "+---------------------+--------+\n",
      "| Epoch tốt nhất      |     30 |\n",
      "| Val Macro F1        | 0.9071 |\n",
      "| Train_eval Macro F1 | 0.9929 |\n",
      "+---------------------+--------+\n",
      "\n",
      "\u001b[32mValidation Set:\u001b[0m\n",
      "           Pred 0   Pred 1\n",
      "  True 0       65        9\n",
      "  True 1        4       62\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.88      0.91        74\n",
      "           1       0.87      0.94      0.91        66\n",
      "\n",
      "    accuracy                           0.91       140\n",
      "   macro avg       0.91      0.91      0.91       140\n",
      "weighted avg       0.91      0.91      0.91       140\n",
      "\n",
      "\n",
      "\u001b[33mTrain_eval Set:\u001b[0m\n",
      "           Pred 0   Pred 1\n",
      "  True 0       58       16\n",
      "  True 1        2       64\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       282\n",
      "           1       0.99      0.99      0.99       278\n",
      "\n",
      "    accuracy                           0.99       560\n",
      "   macro avg       0.99      0.99      0.99       560\n",
      "weighted avg       0.99      0.99      0.99       560\n",
      "\n",
      "\u001b[36m==================================================\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def validate_tms_rnn(subject_embs, labels, net, device):\n",
    "    net.to(device)\n",
    "    net.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        batch_data, batch_lens, _ = lstm_collate([(embs, label) for embs, label in zip(subject_embs, labels)])\n",
    "        batch_data, batch_lens = batch_data.to(device), batch_lens.to(device)\n",
    "        seq_predictions = net.predict_all_timesteps(batch_data, batch_lens)\n",
    "        for seq_pred, true_label in zip(seq_predictions, labels):\n",
    "            idxs = np.nonzero(seq_pred)[0]\n",
    "            predictions.append(seq_pred[idxs[0]] if len(idxs) > 0 else 0)\n",
    "    return {\n",
    "        'acc': metrics.accuracy_score(labels, predictions),\n",
    "        'macro_f1': metrics.f1_score(labels, predictions, average='macro', zero_division=0),\n",
    "        'cls_report': metrics.classification_report(labels, predictions, zero_division=0),\n",
    "        'cfm': metrics.confusion_matrix(labels, predictions)\n",
    "    }\n",
    "def train_gdro_rnn_sl(net, optimizer, device, criterion, train_dl, q, soft_labels, eta=0.1):\n",
    "    net.to(device)\n",
    "    net.train()\n",
    "    loss = 0\n",
    "    num_batches = 0\n",
    "    preds = []\n",
    "    labels = []\n",
    "    for batch_data, batch_lens, batch_labels in train_dl:\n",
    "        labels.append(batch_labels.numpy())\n",
    "        unique_batch_labels = np.unique(batch_labels.numpy())\n",
    "        batch_data, batch_labels = batch_data.to(device), batch_labels.to(device)\n",
    "        batch_lens = batch_lens.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = net(batch_data, batch_lens)\n",
    "        batch_losses = nn.functional.cross_entropy(out, soft_labels[batch_labels], reduction='none')\n",
    "        for cls in unique_batch_labels:\n",
    "            idx_cls = batch_labels == cls\n",
    "            q[cls] *= (eta * batch_losses[idx_cls].mean()).exp().item()\n",
    "        q /= q.sum()\n",
    "        loss_value = sum(q[cls] * batch_losses[batch_labels == cls].mean() for cls in unique_batch_labels)\n",
    "        loss_value.backward()\n",
    "        optimizer.step()\n",
    "        loss += loss_value.item()\n",
    "        num_batches += 1\n",
    "        preds.append(torch.argmax(out, axis=-1).cpu().numpy())\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "    preds = np.concatenate(preds, axis=0)\n",
    "    return {\n",
    "        'loss': loss / num_batches,\n",
    "        'acc': metrics.accuracy_score(labels, preds),\n",
    "        'macro_f1': metrics.f1_score(labels, preds, average='macro', zero_division=0),\n",
    "        'cls_report': metrics.classification_report(labels, preds, zero_division=0),\n",
    "        'cfm': metrics.confusion_matrix(labels, preds)\n",
    "    }, q\n",
    "\n",
    "def run_train_gdro_rnn_sl(net, optimizer, criterion, device, train_dl, train_embs, train_labels,\n",
    "                          val_embs, val_labels, soft_labels, output_dir, max_epochs=150, n_classes=2, eta=0.1):\n",
    "    best_macro_f1_val = 0\n",
    "    logs = {'train': defaultdict(list), 'val': defaultdict(list), 'train_eval': defaultdict(list), 'epoch': 0}\n",
    "    q = torch.ones(n_classes, dtype=torch.float32, device=device) / n_classes\n",
    "    with tqdm(total=max_epochs, desc=\"Training\", bar_format=\"{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}{postfix}]\") as pbar:\n",
    "        for epoch in range(max_epochs):\n",
    "            train_report, q = train_gdro_rnn_sl(net, optimizer, device, criterion, train_dl, q, soft_labels, eta)\n",
    "            logs['train'].update({k: logs['train'][k] + [v] for k, v in train_report.items()})\n",
    "            val_report = validate_tms_rnn(val_embs, val_labels, net, device)\n",
    "            logs['val'].update({k: logs['val'][k] + [v] for k, v in val_report.items()})\n",
    "            pbar.set_postfix({'loss': f\"{train_report['loss']:.4f}\", 'val_f1': f\"{val_report['macro_f1']:.4f}\"})\n",
    "            pbar.update(1)\n",
    "            if val_report['macro_f1'] >= best_macro_f1_val:\n",
    "                best_macro_f1_val = val_report['macro_f1']\n",
    "                torch.save(net.cpu().state_dict(), f'{output_dir}/net_params.pt')\n",
    "                logs['epoch'] = epoch\n",
    "                train_report_eval = validate_tms_rnn(train_embs, train_labels, net, device)\n",
    "                logs['train_eval'].update({k: logs['train_eval'][k] + [v] for k, v in train_report_eval.items()})\n",
    "    return logs\n",
    "\n",
    "def format_confusion_matrix(cfm):\n",
    "    return \"\\n\".join([\n",
    "        f\"{'':>8} {'Pred 0':>8} {'Pred 1':>8}\",\n",
    "        f\"{'True 0':>8} {cfm[0,0]:8d} {cfm[0,1]:8d}\",\n",
    "        f\"{'True 1':>8} {cfm[1,0]:8d} {cfm[1,1]:8d}\"\n",
    "    ])\n",
    "\n",
    "ds = EmbDatasetRNNAug(embs, labels, thr_rng=0.6, n_msg=10)\n",
    "train_ds, test_ds = random_split(ds, [0.8, 0.2], generator=torch.Generator().manual_seed(2909))\n",
    "train_labels = [labels[i] for i in train_ds.indices]\n",
    "test_labels = [labels[i] for i in test_ds.indices]\n",
    "val_embs = [embs[i] for i in test_ds.indices]\n",
    "val_labels = [labels[i] for i in test_ds.indices]\n",
    "train_embs = [embs[i] for i in train_ds.indices]\n",
    "train_labels = [labels[i] for i in train_ds.indices]\n",
    "\n",
    "save_dir = 'pre_trained_models'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "soft_labels = torch.tensor([[0.95, 0.05], [0.05, 0.95]], dtype=torch.float32, device=device)\n",
    "\n",
    "f1s = []\n",
    "for h_size in [96, 128]:\n",
    "    scores = []\n",
    "    for bs in [2, 4, 8]:\n",
    "        dir_name = f'processed_data_h_{h_size}_bs_{bs}_0.95_0.05'\n",
    "        output_dir = os.path.join(save_dir, dir_name)\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        random.seed(2909)\n",
    "        np.random.seed(2909)\n",
    "        torch.manual_seed(2909)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "        train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True, drop_last=False, collate_fn=lstm_collate)\n",
    "        net = LSTMClassifier(embs[0].shape[-1], h_size=h_size, output_dim=2)\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=1e-4)\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "        logs = run_train_gdro_rnn_sl(net, optimizer, loss_fn, device, train_dl, train_embs, train_labels,\n",
    "                                     val_embs, val_labels, soft_labels, output_dir, max_epochs=150)\n",
    "\n",
    "        for k in logs['train_eval']:\n",
    "            if k not in ['cls_report', 'cfm']:\n",
    "                fig, ax = make_plot(logs['train'][k], logs['val'][k], k)\n",
    "                fig.savefig(f'{output_dir}/{k}.png')\n",
    "                plt.close(fig)\n",
    "                fig, ax = make_plot(logs['train_eval'][k], logs['val'][k], k)\n",
    "                fig.savefig(f'{output_dir}/{k}_eval.png')\n",
    "                plt.close(fig)\n",
    "\n",
    "        np.save(f'{output_dir}/logs.npy', logs, allow_pickle=True)\n",
    "\n",
    "        arg = np.argmax(logs['val']['macro_f1'])\n",
    "        table_data = [\n",
    "            [\"Epoch tốt nhất\", arg],\n",
    "            [\"Val Macro F1\", f\"{logs['val']['macro_f1'][arg]:.4f}\"],\n",
    "            [\"Train_eval Macro F1\", f\"{logs['train_eval']['macro_f1'][-1]:.4f}\"]\n",
    "        ]\n",
    "        print(f\"{Fore.CYAN}=== Kết quả cho h_size: {h_size}, batch_size: {bs} ==={Style.RESET_ALL}\")\n",
    "        print(tabulate(table_data, headers=[\"Metric\", \"Value\"], tablefmt=\"pretty\", colalign=(\"left\", \"right\")))\n",
    "        print(f\"\\n{Fore.GREEN}Validation Set:{Style.RESET_ALL}\")\n",
    "        print(format_confusion_matrix(logs['val']['cfm'][arg]))\n",
    "        print(f\"\\n{logs['val']['cls_report'][arg]}\")\n",
    "        print(f\"\\n{Fore.YELLOW}Train_eval Set:{Style.RESET_ALL}\")\n",
    "        print(format_confusion_matrix(logs['val']['cfm'][-1]))\n",
    "        print(f\"\\n{logs['train_eval']['cls_report'][-1]}\")\n",
    "        print(f\"{Fore.CYAN}{'='*50}{Style.RESET_ALL}\\n\")\n",
    "        scores.append(logs['val']['macro_f1'][arg])\n",
    "    f1s.append(scores)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "MentalRisk2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
